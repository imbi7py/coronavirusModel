{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrap Data from KCDC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your path folder to save results\n",
    "PATH_FOLDER_SAVE = '../../data'\n",
    "\n",
    "PATH_CSV_DATA = PATH_FOLDER_SAVE + '/data.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save before scraping\n",
    "\n",
    "import shutil\n",
    "# importing os module\n",
    "import os\n",
    "# import datetime module\n",
    "import datetime\n",
    "\n",
    "\n",
    "def clean_file(path_file_name):\n",
    "    '''\n",
    "    Clean file already traited : rename file with date\n",
    "    '''\n",
    "    try:\n",
    "        d = datetime.datetime.now()\n",
    "        str_date = '_' + d.strftime(\"%Y%m%d_%H_%M_%S\")\n",
    "        res_re = re.search('\\.\\w+$',path_file_name)\n",
    "        path_file_name_saved = \\\n",
    "            path_file_name[0:res_re.start()] + str_date + res_re.group(0)\n",
    "            \n",
    "        shutil.move(path_file_name, path_file_name_saved) \n",
    "        print('File {} moved!'.format(path_file_name_saved))\n",
    "    except:\n",
    "        print('File {} does not exist!'.format(path_file_name))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy\n",
    "import scrapy.crawler as crawler\n",
    "from multiprocessing import Process, Queue\n",
    "from twisted.internet import reactor\n",
    "\n",
    "# the wrapper to make it run more times\n",
    "def run_spider(spider):\n",
    "    '''\n",
    "    function to run several times scraping process\n",
    "    '''\n",
    "    def f(q):\n",
    "        try:\n",
    "            runner = crawler.CrawlerRunner()\n",
    "            deferred = runner.crawl(spider)\n",
    "            deferred.addBoth(lambda _: reactor.stop())\n",
    "            reactor.run()\n",
    "            q.put(None)\n",
    "        except Exception as e:\n",
    "            q.put(e)\n",
    "\n",
    "    q = Queue()\n",
    "    p = Process(target=f, args=(q,))\n",
    "    p.start()\n",
    "    result = q.get()\n",
    "    p.join()\n",
    "\n",
    "    if result is not None:\n",
    "        raise result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "class KCDCPageSpider(scrapy.Spider):\n",
    "    '''\n",
    "    Spider to scrap all Le Gorafi pages from selected category\n",
    "    Configure : \n",
    "    - KCDCPageSpider.custom_settings : save location \n",
    "    - num_max_pages : the number of next page to scrap\n",
    "    - url_first_page : web page to start with\n",
    "    '''\n",
    "    name = \"kcdc_updates_page\"\n",
    "    \n",
    "    custom_settings = {\n",
    "      'FEED_FORMAT': 'json',\n",
    "      'FEED_URI': 'pages_kcdc_updates.json'\n",
    "    }\n",
    "    \n",
    "    num_max_pages = 1\n",
    "    \n",
    "    url_first_page = \\\n",
    "        'https://www.cdc.go.kr/board.es?mid=a30402000000&bid=0030&nPage=1'\n",
    "    \n",
    "    pattern = 'updates'\n",
    "    \n",
    "    def start_requests(self):\n",
    "        urls = [\n",
    "                self.url_first_page,\n",
    "        ]\n",
    "        for url in urls:\n",
    "            yield scrapy.Request(url=url, callback=self.parse)\n",
    "    \n",
    "    def parse(self, response):\n",
    "        #//div[@class=\"dbody\"]/ul/li/a[@title]/@href\n",
    "        #//div[@class=\"dbody\"]/ul/li/a[contains(@title,\"updates\")]/@href\n",
    "        for post in response.xpath(\n",
    "            '//div[@class=\"dbody\"]/ul/li/a[contains(@title,\"updates\")]'):\n",
    "            yield {\n",
    "                'link': post.xpath('@href').extract_first()\n",
    "            }\n",
    "        # https://www.cdc.go.kr/board.es?mid=a30402000000&bid=0030&nPage=2\n",
    "        #//a[@class=\"pageNext\"]/@href\n",
    "        next_page = response.xpath('//a[@class=\"pageNext\"]/@href').get()\n",
    "        \n",
    "        if next_page is not None:\n",
    "            try:\n",
    "                num_next_page = int(re.search(\"(?<=\\&nPage\\=)\\d+$\", \n",
    "                         next_page).group(0))\n",
    "                \n",
    "                if (num_next_page < self.num_max_pages):\n",
    "                    #next_page = response.urljoin(next_page)\n",
    "                    yield scrapy.Request(next_page, callback=self.parse)\n",
    "            except:\n",
    "                next_page = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#int(re.search(\"(?<=\\&nPage\\=)\\d+$\", \n",
    "#                         \"https://www.cdc.go.kr/board.es?mid=a30402000000&bid=0030&nPage=1\").group(0))\n",
    "\n",
    "#response.xpath('//div[@class=\"dbody\"]/ul/li/a[contains(@title,\"updates\")]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL_PAGES_KCDC_UPDATES = \\\n",
    "    \"https://www.cdc.go.kr/board.es?mid=a30402000000&bid=0030&nPage=1\"\n",
    "\n",
    "PATH_PAGES_KCDC_UPDATES = PATH_FOLDER_SAVE + '/pages_kcdc_updates.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ../../data/pages_kcdc_updates.json does not exist!\n"
     ]
    }
   ],
   "source": [
    "# clean (move file if exist)\n",
    "clean_file(PATH_PAGES_KCDC_UPDATES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ../../data/pages_kcdc_updates.json does not exist!\n"
     ]
    }
   ],
   "source": [
    "# configure scraping\n",
    "KCDCPageSpider.url_first_page = URL_PAGES_KCDC_UPDATES\n",
    "KCDCPageSpider.custom_settings = {\n",
    "      'FEED_FORMAT': 'json',\n",
    "      'FEED_URI': URL_PAGES_KCDC_UPDATES\n",
    "    }\n",
    "KCDCPageSpider.num_max_pages = 1\n",
    "\n",
    "# clean last output\n",
    "clean_file(PATH_PAGES_KCDC_UPDATES)\n",
    "# scraping page urls \n",
    "run_spider(KCDCPageSpider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
