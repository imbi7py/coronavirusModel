{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Time Series for COVID: Publish for app\n",
    "\n",
    "This notebook use multistep time serie model  (predicting number of cases future next days).\n",
    "\n",
    "It converts Tensorflow model into TensorFlow Lite to be able to use it in a Lambda fonction on AWS.\n",
    "\n",
    "After that, the lite model is tested and publish on AWS\n",
    "\n",
    "Finally, the lambda function is tested"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert model in TFlite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPORTANT TO DO manually:**\n",
    "- **Update TRAIN_SPLIT in my_helpers.model module**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data useful lib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# helper lib\n",
    "import shutil\n",
    "import os, stat\n",
    "import re\n",
    "import datetime\n",
    "import math\n",
    "\n",
    "# read json from http\n",
    "import json\n",
    "import urllib.request\n",
    "\n",
    "# read csv from http\n",
    "import io\n",
    "import requests\n",
    "\n",
    "# model lib\n",
    "import tensorflow as tf\n",
    "\n",
    "# from project\n",
    "from my_helpers.model import prepare_to_lambda, retrieve_from_lambda\n",
    "from my_helpers.model import prepare_to_lambda_future\n",
    "from my_helpers.model import create_list_past_hist, predict_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN_SPLIT = 135\n"
     ]
    }
   ],
   "source": [
    "PATH_TO_SAVE_DATA = \".\"\n",
    "PATH_DF_POS_FR = PATH_TO_SAVE_DATA + '/' + 'df_pos_fr.csv'\n",
    "PATH_DF_TEST_FR = PATH_TO_SAVE_DATA + '/' + 'df_test_fr.csv'\n",
    "PATH_JSON_METEO_FR = PATH_TO_SAVE_DATA + '/' + 'data_meteo_fr.json'\n",
    "PATH_DF_FEAT_FR = PATH_TO_SAVE_DATA + '/' + 'df_feat_fr.csv' \n",
    "PATH_GEO_DEP_FR = PATH_TO_SAVE_DATA + '/sources/geofrance/' + 'departments.csv'\n",
    "PATH_MDL_SINGLE_STEP = PATH_TO_SAVE_DATA + '/' + \"mdl_single_step_pos_fr\"\n",
    "PATH_MDL_MULTI_STEP = PATH_TO_SAVE_DATA + '/' + \"mdl_multi_step_pos_fr\"\n",
    "PATH_MDL_MULTI_TFLITE = PATH_TO_SAVE_DATA + '/' + \\\n",
    "    'serverless/tensorflow-lite-on-aws-lambda'\n",
    "PATH_MDL_MULTI_TFLITE_FILE = PATH_MDL_MULTI_TFLITE + '/' + \\\n",
    "    \"converted_model.tflite\"\n",
    "PATH_SERVERLESS = PATH_MDL_MULTI_TFLITE + '/' + 'serverless.yml'\n",
    "\n",
    "date_format = \"%Y-%m-%d\"\n",
    "\n",
    "#NB_POS_DATE_MIN_DF_FEAT = 140734 # on 13/05/2020\n",
    "NB_POS_DATE_MIN_DF_FEAT = 140227 # on 12/05/2020\n",
    "\n",
    "URL_PREDICT = 'https://yl0910jrga.execute-api.us-east-2.amazonaws.com/dev/infer'\n",
    "\n",
    "# model \n",
    "PAST_HISTORY = 14 # days used to predict next values in future\n",
    "FUTURE_TARGET = 7 # nb predict days later\n",
    "STEP = 1\n",
    "\n",
    "# plot\n",
    "NB_DAY_PLOT = FUTURE_TARGET*9\n",
    "\n",
    "# train split\n",
    "from my_helpers.model import TRAIN_SPLIT\n",
    "print(f\"TRAIN_SPLIT = {TRAIN_SPLIT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T_min</th>\n",
       "      <th>date</th>\n",
       "      <th>T_max</th>\n",
       "      <th>H_min</th>\n",
       "      <th>H_max</th>\n",
       "      <th>pos</th>\n",
       "      <th>age_pos</th>\n",
       "      <th>test</th>\n",
       "      <th>age_test</th>\n",
       "      <th>day_num</th>\n",
       "      <th>nb_cases</th>\n",
       "      <th>train</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-05-13</th>\n",
       "      <td>284.926667</td>\n",
       "      <td>2020-05-13</td>\n",
       "      <td>290.505000</td>\n",
       "      <td>64.661017</td>\n",
       "      <td>88.135593</td>\n",
       "      <td>882</td>\n",
       "      <td>60.987528</td>\n",
       "      <td>38787</td>\n",
       "      <td>55.444840</td>\n",
       "      <td>3</td>\n",
       "      <td>141109</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-14</th>\n",
       "      <td>285.050000</td>\n",
       "      <td>2020-05-14</td>\n",
       "      <td>290.963333</td>\n",
       "      <td>59.406780</td>\n",
       "      <td>84.847458</td>\n",
       "      <td>980</td>\n",
       "      <td>60.435714</td>\n",
       "      <td>41565</td>\n",
       "      <td>54.798003</td>\n",
       "      <td>4</td>\n",
       "      <td>142089</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-15</th>\n",
       "      <td>285.308333</td>\n",
       "      <td>2020-05-15</td>\n",
       "      <td>291.920000</td>\n",
       "      <td>57.372881</td>\n",
       "      <td>82.966102</td>\n",
       "      <td>1031</td>\n",
       "      <td>59.838991</td>\n",
       "      <td>47019</td>\n",
       "      <td>54.313320</td>\n",
       "      <td>5</td>\n",
       "      <td>143120</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-16</th>\n",
       "      <td>284.956667</td>\n",
       "      <td>2020-05-16</td>\n",
       "      <td>293.500000</td>\n",
       "      <td>53.741379</td>\n",
       "      <td>86.534483</td>\n",
       "      <td>291</td>\n",
       "      <td>60.158076</td>\n",
       "      <td>16145</td>\n",
       "      <td>54.355528</td>\n",
       "      <td>6</td>\n",
       "      <td>143411</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-17</th>\n",
       "      <td>285.598333</td>\n",
       "      <td>2020-05-17</td>\n",
       "      <td>294.446667</td>\n",
       "      <td>49.879310</td>\n",
       "      <td>85.500000</td>\n",
       "      <td>139</td>\n",
       "      <td>61.568345</td>\n",
       "      <td>6270</td>\n",
       "      <td>58.062360</td>\n",
       "      <td>0</td>\n",
       "      <td>143550</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-05</th>\n",
       "      <td>285.878333</td>\n",
       "      <td>2020-10-05</td>\n",
       "      <td>290.990000</td>\n",
       "      <td>67.779661</td>\n",
       "      <td>91.186441</td>\n",
       "      <td>20947</td>\n",
       "      <td>44.384112</td>\n",
       "      <td>178475</td>\n",
       "      <td>46.055268</td>\n",
       "      <td>1</td>\n",
       "      <td>645995</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-06</th>\n",
       "      <td>286.891667</td>\n",
       "      <td>2020-10-06</td>\n",
       "      <td>292.201667</td>\n",
       "      <td>67.508475</td>\n",
       "      <td>89.983051</td>\n",
       "      <td>19020</td>\n",
       "      <td>44.494742</td>\n",
       "      <td>161078</td>\n",
       "      <td>44.712059</td>\n",
       "      <td>2</td>\n",
       "      <td>665015</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-07</th>\n",
       "      <td>286.887288</td>\n",
       "      <td>2020-10-07</td>\n",
       "      <td>292.333051</td>\n",
       "      <td>62.500000</td>\n",
       "      <td>90.655172</td>\n",
       "      <td>20032</td>\n",
       "      <td>43.769020</td>\n",
       "      <td>160191</td>\n",
       "      <td>43.757926</td>\n",
       "      <td>3</td>\n",
       "      <td>685047</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-08</th>\n",
       "      <td>286.931667</td>\n",
       "      <td>2020-10-08</td>\n",
       "      <td>294.066667</td>\n",
       "      <td>63.779661</td>\n",
       "      <td>92.355932</td>\n",
       "      <td>21165</td>\n",
       "      <td>44.015875</td>\n",
       "      <td>169318</td>\n",
       "      <td>44.509190</td>\n",
       "      <td>4</td>\n",
       "      <td>706212</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-09</th>\n",
       "      <td>286.233333</td>\n",
       "      <td>2020-10-09</td>\n",
       "      <td>292.690000</td>\n",
       "      <td>66.762712</td>\n",
       "      <td>93.186441</td>\n",
       "      <td>19936</td>\n",
       "      <td>44.720656</td>\n",
       "      <td>173448</td>\n",
       "      <td>45.304276</td>\n",
       "      <td>5</td>\n",
       "      <td>726148</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 T_min        date       T_max      H_min      H_max    pos  \\\n",
       "date                                                                          \n",
       "2020-05-13  284.926667  2020-05-13  290.505000  64.661017  88.135593    882   \n",
       "2020-05-14  285.050000  2020-05-14  290.963333  59.406780  84.847458    980   \n",
       "2020-05-15  285.308333  2020-05-15  291.920000  57.372881  82.966102   1031   \n",
       "2020-05-16  284.956667  2020-05-16  293.500000  53.741379  86.534483    291   \n",
       "2020-05-17  285.598333  2020-05-17  294.446667  49.879310  85.500000    139   \n",
       "...                ...         ...         ...        ...        ...    ...   \n",
       "2020-10-05  285.878333  2020-10-05  290.990000  67.779661  91.186441  20947   \n",
       "2020-10-06  286.891667  2020-10-06  292.201667  67.508475  89.983051  19020   \n",
       "2020-10-07  286.887288  2020-10-07  292.333051  62.500000  90.655172  20032   \n",
       "2020-10-08  286.931667  2020-10-08  294.066667  63.779661  92.355932  21165   \n",
       "2020-10-09  286.233333  2020-10-09  292.690000  66.762712  93.186441  19936   \n",
       "\n",
       "              age_pos    test   age_test  day_num  nb_cases  train  \n",
       "date                                                                \n",
       "2020-05-13  60.987528   38787  55.444840        3    141109   True  \n",
       "2020-05-14  60.435714   41565  54.798003        4    142089   True  \n",
       "2020-05-15  59.838991   47019  54.313320        5    143120   True  \n",
       "2020-05-16  60.158076   16145  54.355528        6    143411   True  \n",
       "2020-05-17  61.568345    6270  58.062360        0    143550   True  \n",
       "...               ...     ...        ...      ...       ...    ...  \n",
       "2020-10-05  44.384112  178475  46.055268        1    645995  False  \n",
       "2020-10-06  44.494742  161078  44.712059        2    665015  False  \n",
       "2020-10-07  43.769020  160191  43.757926        3    685047  False  \n",
       "2020-10-08  44.015875  169318  44.509190        4    706212  False  \n",
       "2020-10-09  44.720656  173448  45.304276        5    726148  False  \n",
       "\n",
       "[150 rows x 12 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_feat_fr = pd.read_csv(PATH_DF_FEAT_FR)\n",
    "df_feat_fr.index = df_feat_fr[\"date\"]\n",
    "df_feat_fr[\"train\"] = [True if I <= TRAIN_SPLIT else False \\\n",
    "                       for I in range(df_feat_fr.shape[0])]\n",
    "df_feat_fr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prepare features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T_min</th>\n",
       "      <th>T_max</th>\n",
       "      <th>H_min</th>\n",
       "      <th>H_max</th>\n",
       "      <th>pos</th>\n",
       "      <th>test</th>\n",
       "      <th>day_num</th>\n",
       "      <th>age_pos</th>\n",
       "      <th>age_test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-05-13</th>\n",
       "      <td>284.926667</td>\n",
       "      <td>290.505000</td>\n",
       "      <td>64.661017</td>\n",
       "      <td>88.135593</td>\n",
       "      <td>882</td>\n",
       "      <td>38787</td>\n",
       "      <td>3</td>\n",
       "      <td>60.987528</td>\n",
       "      <td>55.444840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-14</th>\n",
       "      <td>285.050000</td>\n",
       "      <td>290.963333</td>\n",
       "      <td>59.406780</td>\n",
       "      <td>84.847458</td>\n",
       "      <td>980</td>\n",
       "      <td>41565</td>\n",
       "      <td>4</td>\n",
       "      <td>60.435714</td>\n",
       "      <td>54.798003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-15</th>\n",
       "      <td>285.308333</td>\n",
       "      <td>291.920000</td>\n",
       "      <td>57.372881</td>\n",
       "      <td>82.966102</td>\n",
       "      <td>1031</td>\n",
       "      <td>47019</td>\n",
       "      <td>5</td>\n",
       "      <td>59.838991</td>\n",
       "      <td>54.313320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-16</th>\n",
       "      <td>284.956667</td>\n",
       "      <td>293.500000</td>\n",
       "      <td>53.741379</td>\n",
       "      <td>86.534483</td>\n",
       "      <td>291</td>\n",
       "      <td>16145</td>\n",
       "      <td>6</td>\n",
       "      <td>60.158076</td>\n",
       "      <td>54.355528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-17</th>\n",
       "      <td>285.598333</td>\n",
       "      <td>294.446667</td>\n",
       "      <td>49.879310</td>\n",
       "      <td>85.500000</td>\n",
       "      <td>139</td>\n",
       "      <td>6270</td>\n",
       "      <td>0</td>\n",
       "      <td>61.568345</td>\n",
       "      <td>58.062360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-05</th>\n",
       "      <td>285.878333</td>\n",
       "      <td>290.990000</td>\n",
       "      <td>67.779661</td>\n",
       "      <td>91.186441</td>\n",
       "      <td>20947</td>\n",
       "      <td>178475</td>\n",
       "      <td>1</td>\n",
       "      <td>44.384112</td>\n",
       "      <td>46.055268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-06</th>\n",
       "      <td>286.891667</td>\n",
       "      <td>292.201667</td>\n",
       "      <td>67.508475</td>\n",
       "      <td>89.983051</td>\n",
       "      <td>19020</td>\n",
       "      <td>161078</td>\n",
       "      <td>2</td>\n",
       "      <td>44.494742</td>\n",
       "      <td>44.712059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-07</th>\n",
       "      <td>286.887288</td>\n",
       "      <td>292.333051</td>\n",
       "      <td>62.500000</td>\n",
       "      <td>90.655172</td>\n",
       "      <td>20032</td>\n",
       "      <td>160191</td>\n",
       "      <td>3</td>\n",
       "      <td>43.769020</td>\n",
       "      <td>43.757926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-08</th>\n",
       "      <td>286.931667</td>\n",
       "      <td>294.066667</td>\n",
       "      <td>63.779661</td>\n",
       "      <td>92.355932</td>\n",
       "      <td>21165</td>\n",
       "      <td>169318</td>\n",
       "      <td>4</td>\n",
       "      <td>44.015875</td>\n",
       "      <td>44.509190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-09</th>\n",
       "      <td>286.233333</td>\n",
       "      <td>292.690000</td>\n",
       "      <td>66.762712</td>\n",
       "      <td>93.186441</td>\n",
       "      <td>19936</td>\n",
       "      <td>173448</td>\n",
       "      <td>5</td>\n",
       "      <td>44.720656</td>\n",
       "      <td>45.304276</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 T_min       T_max      H_min      H_max    pos    test  \\\n",
       "date                                                                      \n",
       "2020-05-13  284.926667  290.505000  64.661017  88.135593    882   38787   \n",
       "2020-05-14  285.050000  290.963333  59.406780  84.847458    980   41565   \n",
       "2020-05-15  285.308333  291.920000  57.372881  82.966102   1031   47019   \n",
       "2020-05-16  284.956667  293.500000  53.741379  86.534483    291   16145   \n",
       "2020-05-17  285.598333  294.446667  49.879310  85.500000    139    6270   \n",
       "...                ...         ...        ...        ...    ...     ...   \n",
       "2020-10-05  285.878333  290.990000  67.779661  91.186441  20947  178475   \n",
       "2020-10-06  286.891667  292.201667  67.508475  89.983051  19020  161078   \n",
       "2020-10-07  286.887288  292.333051  62.500000  90.655172  20032  160191   \n",
       "2020-10-08  286.931667  294.066667  63.779661  92.355932  21165  169318   \n",
       "2020-10-09  286.233333  292.690000  66.762712  93.186441  19936  173448   \n",
       "\n",
       "            day_num    age_pos   age_test  \n",
       "date                                       \n",
       "2020-05-13        3  60.987528  55.444840  \n",
       "2020-05-14        4  60.435714  54.798003  \n",
       "2020-05-15        5  59.838991  54.313320  \n",
       "2020-05-16        6  60.158076  54.355528  \n",
       "2020-05-17        0  61.568345  58.062360  \n",
       "...             ...        ...        ...  \n",
       "2020-10-05        1  44.384112  46.055268  \n",
       "2020-10-06        2  44.494742  44.712059  \n",
       "2020-10-07        3  43.769020  43.757926  \n",
       "2020-10-08        4  44.015875  44.509190  \n",
       "2020-10-09        5  44.720656  45.304276  \n",
       "\n",
       "[150 rows x 9 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = df_feat_fr.copy().filter(items=['T_min', 'T_max', 'H_min',\n",
    "                                           'H_max', 'pos', 'test', 'day_num',\n",
    "                                          'age_pos', 'age_test'])\n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = features.values\n",
    "data_mean = dataset[:TRAIN_SPLIT].mean(axis=0)\n",
    "data_std = dataset[:TRAIN_SPLIT].std(axis=0)\n",
    "dataset = (dataset-data_mean)/data_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PAST_HISTORY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.recurrent_v2.LSTM object at 0x64022a3d0> and <tensorflow.python.keras.layers.core.Dropout object at 0x6402a1350>).\n",
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x6402a1bd0> and <tensorflow.python.keras.layers.core.Dense object at 0x6402b51d0>).\n",
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x6402a1bd0> and <tensorflow.python.keras.layers.core.Dropout object at 0x6402a1350>).\n",
      "CPU times: user 2.11 s, sys: 152 ms, total: 2.26 s\n",
      "Wall time: 2.68 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# reload best model\n",
    "multi_step_model = tf.keras.models.load_model(PATH_MDL_MULTI_STEP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf.float32"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_step_model.inputs[0].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/envs/coronavirusModel/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From /anaconda3/envs/coronavirusModel/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: ./keras_lstm/assets\n"
     ]
    }
   ],
   "source": [
    "run_model = tf.function(lambda x: multi_step_model(x))\n",
    "# This is important, let's fix the input size.\n",
    "INPUT_SIZE = dataset.shape[1]\n",
    "concrete_func = run_model.get_concrete_function(\n",
    "    tf.TensorSpec([1, PAST_HISTORY, INPUT_SIZE],\n",
    "                  multi_step_model.inputs[0].dtype))\n",
    "\n",
    "# model directory.\n",
    "MODEL_DIR = PATH_TO_SAVE_DATA + \"/\" + \"keras_lstm\"\n",
    "multi_step_model.save(MODEL_DIR, save_format=\"tf\", signatures=concrete_func)\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(MODEL_DIR)\n",
    "\n",
    "'''converter.target_spec.supported_ops = [\n",
    "  tf.lite.OpsSet.TFLITE_BUILTINS, # enable TensorFlow Lite ops.\n",
    "  tf.lite.OpsSet.SELECT_TF_OPS # enable TensorFlow ops.\n",
    "]\n",
    "converter.allow_custom_ops=True'''\n",
    "\n",
    "tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model TFlite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ./serverless/tensorflow-lite-on-aws-lambda/converted_model_20201013_16_10_52.tflite moved!\n"
     ]
    }
   ],
   "source": [
    "clean_file(PATH_MDL_MULTI_TFLITE_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6104"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open(PATH_MDL_MULTI_TFLITE_FILE, \"wb\").write(tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test converted model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict with TFlite & Compare "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[58 - 72]\n",
      "[65 - 79]\n",
      "[72 - 86]\n",
      "[79 - 93]\n",
      "[86 - 100]\n",
      "[93 - 107]\n",
      "[100 - 114]\n",
      "[107 - 121]\n",
      "[114 - 128]\n",
      "9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  794.53906,   573.5635 ,   737.1929 ,   900.4518 ,  1174.9934 ,\n",
       "         1443.3275 ,  1514.0929 ,  1121.9463 ,   728.1682 ,  1069.7264 ,\n",
       "         1386.3137 ,  1821.1062 ,  2134.7217 ,  2111.8508 ,  1611.0874 ,\n",
       "         1343.4803 ,  1666.6522 ,  1936.792  ,  2481.4824 ,  2893.221  ,\n",
       "         2925.7922 ,  2851.1912 ,  2217.1235 ,  2752.3496 ,  3274.1917 ,\n",
       "         4321.4863 ,  4639.918  ,  4477.752  ,  4013.4312 ,  2749.5015 ,\n",
       "         3690.4539 ,  4731.7075 ,  6523.2383 ,  6793.405  ,  6274.082  ,\n",
       "         6107.8823 ,  3913.3142 ,  4726.2705 ,  6161.127  ,  9262.326  ,\n",
       "         9705.555  ,  8793.442  ,  8174.411  ,  4993.5337 ,  5670.9854 ,\n",
       "         7451.4326 , 11373.937  , 11368.053  , 10189.23   ,  9129.875  ,\n",
       "         5029.9014 ,  6804.997  ,  9114.3    , 12794.654  , 12615.478  ,\n",
       "        11984.076  , 10026.873  ,  5788.4688 ,  7669.9277 , 10158.219  ,\n",
       "        13777.826  , 12801.566  , 11832.221  ]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TENSORFLOW MODEL :\n",
    "# prepare list of past histories\n",
    "list_x = create_list_past_hist(dataset)\n",
    "# predict\n",
    "y_multi_pred = predict_list(list_x, multi_step_model)\n",
    "# convert in positive cases\n",
    "y_pos_pred = (y_multi_pred * data_std[4]) + data_mean[4] \n",
    "y_pos_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n",
      "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n",
      "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n",
      "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n",
      "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n",
      "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n",
      "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n",
      "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n",
      "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n"
     ]
    }
   ],
   "source": [
    "# CONVERTED LITE MODEL\n",
    "# load \n",
    "interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
    "\n",
    "# Run the model with TensorFlow Lite\n",
    "interpreter.allocate_tensors()\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# check if same results \n",
    "for x_multi in list_x:\n",
    "    # predict with tensorflow model\n",
    "    expected = multi_step_model.predict(x_multi)\n",
    "    # predict with TFlite model\n",
    "    interpreter.set_tensor(input_details[0][\"index\"], \n",
    "                           x_multi.astype(np.float32))\n",
    "    interpreter.invoke()\n",
    "    result = interpreter.get_tensor(output_details[0][\"index\"])\n",
    "\n",
    "    # Assert if the result of TFLite model is consistent with the TF model.\n",
    "    np.testing.assert_almost_equal(expected, result, decimal=3)\n",
    "    print(\"Done. The result of TensorFlow matches the result of TensorFlow Lite.\")\n",
    "\n",
    "    # Please note: TfLite fused Lstm kernel is stateful, so we need to reset\n",
    "    # the states.\n",
    "    # Clean up internal states.\n",
    "    interpreter.reset_all_variables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reload Tlite model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path=PATH_MDL_MULTI_TFLITE_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./serverless/tensorflow-lite-on-aws-lambda/converted_model.tflite'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH_MDL_MULTI_TFLITE_FILE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict reloaded model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n",
      "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n",
      "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n",
      "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n",
      "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n",
      "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n",
      "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n",
      "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n",
      "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n"
     ]
    }
   ],
   "source": [
    "# Run the model with TensorFlow Lite\n",
    "interpreter.allocate_tensors()\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# check if same results \n",
    "for x_multi in list_x:\n",
    "    \n",
    "    expected = multi_step_model.predict(x_multi)\n",
    "    \n",
    "    interpreter.set_tensor(input_details[0][\"index\"], \n",
    "                           x_multi.astype(np.float32))\n",
    "    interpreter.invoke()\n",
    "    result = interpreter.get_tensor(output_details[0][\"index\"])\n",
    "\n",
    "    # Assert if the result of TFLite model is consistent with the TF model.\n",
    "    np.testing.assert_almost_equal(expected, result, decimal=3)\n",
    "    print(\"Done. The result of TensorFlow matches the result of TensorFlow Lite.\")\n",
    "\n",
    "    # Please note: TfLite fused Lstm kernel is stateful, so we need to reset\n",
    "    # the states.\n",
    "    # Clean up internal states.\n",
    "    interpreter.reset_all_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 14, 9)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_multi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update API lambda AWS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API lambda simulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 9)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[58 - 72]\n",
      "[65 - 79]\n",
      "[72 - 86]\n",
      "[79 - 93]\n",
      "[86 - 100]\n",
      "[93 - 107]\n",
      "[100 - 114]\n",
      "[107 - 121]\n",
      "[114 - 128]\n"
     ]
    }
   ],
   "source": [
    "json_list_list_x = prepare_to_lambda(dataset)\n",
    "# simulate input to lambda (double dumps ? why ? i don't know yet)\n",
    "json_list_list_x = json.dumps(json_list_list_x)\n",
    "# simulate lambda\n",
    "\n",
    "event = {\"body\": json_list_list_x}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"[[[[0.8661074471642011, -0.02564300546570835, 0.3\n",
      "INPUT : nb. arrays : 9 / arrays shape: (1, 14, 9)\n",
      "OUTPUT : nb. arrays : 9 / arrays shape in list: (1, 7)\n"
     ]
    }
   ],
   "source": [
    "# patch for simulate import in AWS\n",
    "import tensorflow.lite as tflite\n",
    "\n",
    "# lambda code (file ./serverless/tensorflow-lite-on-aws-lambda/handler.py)\n",
    "def predict(event, context):\n",
    "    # retrieve entry event -> json_list_list_x\n",
    "    json_list_list_x = event.get('body')\n",
    "    print(json_list_list_x[0:50])\n",
    "    list_list_in = json.loads(json.loads(json_list_list_x))\n",
    "    # convert in list of array\n",
    "    # retrieve json into lambda\n",
    "    list_arr_in = []\n",
    "    for list_curr in list_list_in:\n",
    "        list_arr_in.append(np.array(list_curr))\n",
    "\n",
    "    print(\"INPUT : nb. arrays : {} / arrays shape: {}\".format(len(list_arr_in), \n",
    "                                             list_arr_in[0].shape))\n",
    "\n",
    "    # prepare TFlite model\n",
    "    interpreter = tflite.Interpreter(model_path=PATH_MDL_MULTI_TFLITE_FILE)\n",
    "    interpreter.allocate_tensors()\n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "\n",
    "\n",
    "    # Run the model with TensorFlow Lite\n",
    "    list_list_out = []\n",
    "    for x_multi in list_arr_in:\n",
    "        interpreter.set_tensor(input_details[0][\"index\"], \n",
    "                               x_multi.astype(np.float32))\n",
    "        interpreter.invoke()\n",
    "        result = interpreter.get_tensor(output_details[0][\"index\"])\n",
    "        list_list_out.append(result.tolist())\n",
    "        # Please note: TfLite fused Lstm kernel is stateful, so we need to reset\n",
    "        # the states.\n",
    "        # Clean up internal states.\n",
    "        interpreter.reset_all_variables()\n",
    "    print(\"OUTPUT : nb. arrays : {} / arrays shape in list: {}\" \\\n",
    "          .format(len(list_list_out), np.array(list_list_out[0]).shape))\n",
    "\n",
    "    # Prepare output\n",
    "    json_list_list_out = json.dumps(list_list_out)\n",
    "    response = {\n",
    "        \"statusCode\": 200,\n",
    "        \"body\": json_list_list_out\n",
    "    }\n",
    "    return response\n",
    "\n",
    "context = None\n",
    "response = predict(event, context)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 63)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve from lambda in App code\n",
    "# input : response\n",
    "y_multi_pred_out = retrieve_from_lambda(response)      \n",
    "y_multi_pred_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.5215902 , -0.5768285 , -0.53592527, -0.49511465, -0.4264862 ,\n",
       "        -0.35940948, -0.34171993, -0.43974665, -0.5381812 , -0.45280027,\n",
       "        -0.3736615 , -0.2649744 , -0.18657842, -0.19229557, -0.31747374,\n",
       "        -0.38436875, -0.30358395, -0.23605584, -0.09989706,  0.00302715,\n",
       "         0.01116916, -0.00747924, -0.16598004, -0.0321871 ,  0.09826019,\n",
       "         0.36005735,  0.4396572 ,  0.3991198 ,  0.28305134, -0.03289908,\n",
       "         0.20231518,  0.4626022 ,  0.91043955,  0.97797436,  0.8481568 ,\n",
       "         0.80661106,  0.25802463,  0.46124315,  0.81992096,  1.5951422 ,\n",
       "         1.705938  ,  1.4779332 ,  1.3231909 ,  0.52805215,  0.69739795,\n",
       "         1.1424645 ,  2.122991  ,  2.1215203 ,  1.8268447 ,  1.5620328 ,\n",
       "         0.53714323,  0.9808721 ,  1.5581393 ,  2.4781346 ,  2.433345  ,\n",
       "         2.2755105 ,  1.7862595 ,  0.7267658 ,  1.1970828 ,  1.8190925 ,\n",
       "         2.7239027 ,  2.4798625 ,  2.2375507 ]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_multi_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.52159017, -0.57682848, -0.53592527, -0.49511465, -0.42648619,\n",
       "        -0.35940948, -0.34171993, -0.43974674, -0.53818125, -0.45280027,\n",
       "        -0.37366149, -0.26497436, -0.18657845, -0.19229554, -0.31747374,\n",
       "        -0.38436875, -0.30358392, -0.23605584, -0.09989709,  0.00302715,\n",
       "         0.01116917, -0.00747922, -0.16598004, -0.03218707,  0.09826022,\n",
       "         0.36005738,  0.43965727,  0.39911985,  0.28305134, -0.0328991 ,\n",
       "         0.20231497,  0.46260199,  0.91043949,  0.9779743 ,  0.84815669,\n",
       "         0.806611  ,  0.2580246 ,  0.46124333,  0.81992114,  1.59514225,\n",
       "         1.70593798,  1.47793329,  1.32319105,  0.52805221,  0.69739789,\n",
       "         1.1424644 ,  2.12299085,  2.12152004,  1.82684469,  1.56203282,\n",
       "         0.53714323,  0.98087209,  1.55813932,  2.47813416,  2.4333446 ,\n",
       "         2.27551055,  1.78625953,  0.72676569,  1.19708264,  1.81909239,\n",
       "         2.7239027 ,  2.47986221,  2.2375505 ]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_multi_pred_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n"
     ]
    }
   ],
   "source": [
    "# Assert if the result of TFLite model is consistent with the TF model.\n",
    "np.testing.assert_almost_equal(y_multi_pred, y_multi_pred_out, decimal=3)\n",
    "print(\"Done. The result of TensorFlow matches the result of TensorFlow Lite.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"[[[[-2.324386895944945, -2.639625843078335, 0.768\n",
      "INPUT : nb. arrays : 1 / arrays shape: (1, 14, 9)\n",
      "OUTPUT : nb. arrays : 1 / arrays shape in list: (1, 7)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 7)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare data to lambda (future)\n",
    "json_list_list_x = prepare_to_lambda_future(dataset)\n",
    "\n",
    "# simulate lambda\n",
    "json_list_list_x = json.dumps(json_list_list_x) # dumps again : I dont know why\n",
    "event = {\"body\": json_list_list_x}\n",
    "context = None\n",
    "response = predict(event, context)\n",
    "y_future_pred_out = retrieve_from_lambda(response)      \n",
    "y_future_pred_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data : very last days\n",
    "x_for_future = np.array([dataset[-PAST_HISTORY:,:]]) \n",
    "# predict next days\n",
    "y_future_pred = multi_step_model.predict(x_for_future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.25671518, 0.26149568, 0.71327579, 1.26555955, 2.33228302,\n",
       "        2.35756588, 1.97211969]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_future_pred_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.2567154, 0.2614957, 0.7132758, 1.2655597, 2.3322833, 2.3575656,\n",
       "        1.9721197]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_future_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n"
     ]
    }
   ],
   "source": [
    "# Assert if the result of TFLite model is consistent with the TF model.\n",
    "np.testing.assert_almost_equal(y_future_pred, y_future_pred_out, decimal=3)\n",
    "print(\"Done. The result of TensorFlow matches the result of TensorFlow Lite.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update AWS Lambda with new model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part does:\n",
    "- Go to : ./serverless//tensorflow-lite-on-aws-lambda\n",
    "    \n",
    "- Execute : sls deploy -v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#!/bin/bash\\nexport PATH=\"/usr/local/bin:$PATH\"\\ncd ./serverless/tensorflow-lite-on-aws-lambda\\nserverless deploy -v'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str_exe = '#!/bin/bash\\n' + \\\n",
    "    'export PATH=\"/usr/local/bin:$PATH\"\\n' + \\\n",
    "    f'cd {PATH_MDL_MULTI_TFLITE}\\n' + \\\n",
    "    'serverless deploy -v'\n",
    "str_exe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "open('deploy_serverless.sh', \"w\").write(str_exe)\n",
    "os.chmod('deploy_serverless.sh', stat.S_IRWXU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/bin/bash\r\n",
      "export PATH=\"/usr/local/bin:$PATH\"\r\n",
      "cd ./serverless/tensorflow-lite-on-aws-lambda\r\n",
      "serverless deploy -v"
     ]
    }
   ],
   "source": [
    "!cat ./deploy_serverless.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serverless: \u001b[33mGenerated requirements from /Users/gregory/Documents/CloudStationSinchon/Applications/python/CoronaVirus/code/coronavirusModel/serverless/tensorflow-lite-on-aws-lambda/requirements.txt in /Users/gregory/Documents/CloudStationSinchon/Applications/python/CoronaVirus/code/coronavirusModel/serverless/tensorflow-lite-on-aws-lambda/.serverless/requirements.txt...\u001b[39m\n",
      "Serverless: \u001b[33mUsing static cache of requirements found at /Users/gregory/Library/Caches/serverless-python-requirements/ef4e42eb03bbad46f74fee99a3c01f994e8119e7a557f947779093ab37b248d3_slspyc ...\u001b[39m\n",
      "Serverless: \u001b[33mPackaging service...\u001b[39m\n",
      "Serverless: \u001b[33mExcluding development dependencies...\u001b[39m\n",
      "Serverless: \u001b[33mInjecting required Python packages to package...\u001b[39m\n",
      "Serverless: \u001b[33mUploading CloudFormation file to S3...\u001b[39m\n",
      "Serverless: \u001b[33mUploading artifacts...\u001b[39m\n",
      "Serverless: \u001b[33mUploading service tensorflow-lite-on-aws-lambda.zip file to S3 (18.4 MB)...\u001b[39m\n",
      "Serverless: \u001b[33mValidating template...\u001b[39m\n",
      "Serverless: \u001b[33mUpdating Stack...\u001b[39m\n",
      "Serverless: \u001b[33mChecking Stack update progress...\u001b[39m\n",
      "CloudFormation - \u001b[33mUPDATE_IN_PROGRESS\u001b[39m - AWS::CloudFormation::Stack - tensorflow-lite-on-aws-lambda-dev\n",
      "CloudFormation - \u001b[33mUPDATE_IN_PROGRESS\u001b[39m - AWS::Lambda::Function - PredictLambdaFunction\n",
      "CloudFormation - \u001b[32mUPDATE_COMPLETE\u001b[39m - AWS::Lambda::Function - PredictLambdaFunction\n",
      "CloudFormation - \u001b[33mCREATE_IN_PROGRESS\u001b[39m - AWS::Lambda::Version - PredictLambdaVersion94SXertKJfYwEBHrgbB0A4IlgWF6Cq1ivL25fiIcw\n",
      "CloudFormation - \u001b[33mCREATE_IN_PROGRESS\u001b[39m - AWS::Lambda::Version - PredictLambdaVersion94SXertKJfYwEBHrgbB0A4IlgWF6Cq1ivL25fiIcw\n",
      "CloudFormation - \u001b[32mCREATE_COMPLETE\u001b[39m - AWS::Lambda::Version - PredictLambdaVersion94SXertKJfYwEBHrgbB0A4IlgWF6Cq1ivL25fiIcw\n",
      "CloudFormation - \u001b[33mCREATE_IN_PROGRESS\u001b[39m - AWS::ApiGateway::Deployment - ApiGatewayDeployment1602580073981\n",
      "CloudFormation - \u001b[33mCREATE_IN_PROGRESS\u001b[39m - AWS::ApiGateway::Deployment - ApiGatewayDeployment1602580073981\n",
      "CloudFormation - \u001b[32mCREATE_COMPLETE\u001b[39m - AWS::ApiGateway::Deployment - ApiGatewayDeployment1602580073981\n",
      "CloudFormation - \u001b[33mUPDATE_COMPLETE_CLEANUP_IN_PROGRESS\u001b[39m - AWS::CloudFormation::Stack - tensorflow-lite-on-aws-lambda-dev\n",
      "CloudFormation - \u001b[33mDELETE_IN_PROGRESS\u001b[39m - AWS::ApiGateway::Deployment - ApiGatewayDeployment1600667194069\n",
      "CloudFormation - DELETE_SKIPPED - AWS::Lambda::Version - PredictLambdaVersionF6298Z1GDB0EKVctzpkflG427bRvaUiVE9E08ipgI\n",
      "CloudFormation - \u001b[32mDELETE_COMPLETE\u001b[39m - AWS::ApiGateway::Deployment - ApiGatewayDeployment1600667194069\n",
      "CloudFormation - \u001b[32mUPDATE_COMPLETE\u001b[39m - AWS::CloudFormation::Stack - tensorflow-lite-on-aws-lambda-dev\n",
      "Serverless: \u001b[33mStack update finished...\u001b[39m\n",
      "\u001b[33m\u001b[4mService Information\u001b[24m\u001b[39m\n",
      "\u001b[33mservice:\u001b[39m tensorflow-lite-on-aws-lambda\n",
      "\u001b[33mstage:\u001b[39m dev\n",
      "\u001b[33mregion:\u001b[39m us-east-2\n",
      "\u001b[33mstack:\u001b[39m tensorflow-lite-on-aws-lambda-dev\n",
      "\u001b[33mresources:\u001b[39m 11\n",
      "\u001b[33mapi keys:\u001b[39m\n",
      "  None\n",
      "\u001b[33mendpoints:\u001b[39m\n",
      "  POST - https://yl0910jrga.execute-api.us-east-2.amazonaws.com/dev/infer\n",
      "\u001b[33mfunctions:\u001b[39m\n",
      "  predict: tensorflow-lite-on-aws-lambda-dev-predict\n",
      "\u001b[33mlayers:\u001b[39m\n",
      "  None\n",
      "\u001b[33m\u001b[4m\u001b[24m\u001b[39m\n",
      "\u001b[33m\u001b[4mStack Outputs\u001b[24m\u001b[39m\n",
      "\u001b[33m\u001b[4m\u001b[24m\u001b[39m\u001b[33mPredictLambdaFunctionQualifiedArn\u001b[39m: arn:aws:lambda:us-east-2:324466407431:function:tensorflow-lite-on-aws-lambda-dev-predict:9\n",
      "\u001b[33mServiceEndpoint\u001b[39m: https://yl0910jrga.execute-api.us-east-2.amazonaws.com/dev\n",
      "\u001b[33mServerlessDeploymentBucketName\u001b[39m: tensorflow-lite-on-aws-l-serverlessdeploymentbuck-1vuz80v36l59q\n",
      "\n",
      "Serverless: \u001b[33mRemoving old service artifacts from S3...\u001b[39m\n",
      "\n",
      "********************************************************************************\n",
      "Serverless: \u001b[33mAnnouncing Metrics, CI/CD, Secrets and more built into Serverless Framework. Run \"serverless login\" to activate for free..\u001b[39m\n",
      "********************************************************************************\n",
      "\n",
      "\n",
      "\u001b[33m\u001b[39m\n",
      "\u001b[33m   ╭───────────────────────────────────────╮\u001b[39m\n",
      "   \u001b[33m│\u001b[39m                                       \u001b[33m│\u001b[39m\n",
      "   \u001b[33m│\u001b[39m   Update available \u001b[2m1.79.0\u001b[22m\u001b[0m → \u001b[0m\u001b[32m2.1.1\u001b[39m     \u001b[33m│\u001b[39m\n",
      "   \u001b[33m│\u001b[39m   Run \u001b[36mnpm i -g serverless\u001b[39m to update   \u001b[33m│\u001b[39m\n",
      "   \u001b[33m│\u001b[39m                                       \u001b[33m│\u001b[39m\n",
      "\u001b[33m   ╰───────────────────────────────────────╯\u001b[39m\n",
      "\u001b[33m\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "!./deploy_serverless.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API AWS real Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[58 - 72]\n",
      "[65 - 79]\n",
      "[72 - 86]\n",
      "[79 - 93]\n",
      "[86 - 100]\n",
      "[93 - 107]\n",
      "[100 - 114]\n",
      "[107 - 121]\n",
      "[114 - 128]\n",
      "status code :  200\n",
      "[[[-0.5216001272201538, -0.5768371820449829, -0.5359305739402771, -0.4951191246509552, -0.42649587988853455, -0.35942143201828003, -0.34173017740249634]], [[-0.43972229957580566, -0.5381525158882141, -0.4527134299278259, -0.3735485374927521, -0.2648811340332031, -0.18651607632637024, -0.19224025309085846]], [[-0.3174644708633423, -0.38433074951171875, -0.30356526374816895, -0.23604823648929596, -0.09988704323768616, 0.00302993506193161, 0.011154964566230774]], [[-0.007503926753997803, -0.16600263118743896, -0.03220542520284653, 0.09823962301015854, 0.3600359559059143, 0.4396497905254364, 0.39911484718322754]], [[0.2830981910228729, -0.03286878764629364, 0.20234274864196777, 0.4626409113407135, 0.910483717918396, 0.9779927134513855, 0.8481712937355042]], [[0.80661541223526, 0.25803759694099426, 0.4612640142440796, 0.8199437856674194, 1.5951529741287231, 1.7059340476989746, 1.477924108505249]], [[1.3232253789901733, 0.5280614495277405, 0.6974382996559143, 1.142532229423523, 2.1230416297912598, 2.1215271949768066, 1.8268533945083618]], [[1.562026858329773, 0.5371406674385071, 0.980837345123291, 1.5580981969833374, 2.478116273880005, 2.433326005935669, 2.275474786758423]], [[1.7862745523452759, 0.7267669439315796, 1.1970322132110596, 1.8190288543701172, 2.7238829135894775, 2.4798614978790283, 2.2375428676605225]]]\n"
     ]
    }
   ],
   "source": [
    "# prepare input\n",
    "json_list_list_x = prepare_to_lambda(dataset)\n",
    "# REQUEST\n",
    "resp = requests.post(URL_PREDICT, json=json_list_list_x)\n",
    "print(\"status code : \", resp.status_code) \n",
    "print(resp.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23745"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(json_list_list_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[-0.5216001272201538,\n",
       "   -0.5768371820449829,\n",
       "   -0.5359305739402771,\n",
       "   -0.4951191246509552,\n",
       "   -0.42649587988853455,\n",
       "   -0.35942143201828003,\n",
       "   -0.34173017740249634]],\n",
       " [[-0.43972229957580566,\n",
       "   -0.5381525158882141,\n",
       "   -0.4527134299278259,\n",
       "   -0.3735485374927521,\n",
       "   -0.2648811340332031,\n",
       "   -0.18651607632637024,\n",
       "   -0.19224025309085846]],\n",
       " [[-0.3174644708633423,\n",
       "   -0.38433074951171875,\n",
       "   -0.30356526374816895,\n",
       "   -0.23604823648929596,\n",
       "   -0.09988704323768616,\n",
       "   0.00302993506193161,\n",
       "   0.011154964566230774]],\n",
       " [[-0.007503926753997803,\n",
       "   -0.16600263118743896,\n",
       "   -0.03220542520284653,\n",
       "   0.09823962301015854,\n",
       "   0.3600359559059143,\n",
       "   0.4396497905254364,\n",
       "   0.39911484718322754]],\n",
       " [[0.2830981910228729,\n",
       "   -0.03286878764629364,\n",
       "   0.20234274864196777,\n",
       "   0.4626409113407135,\n",
       "   0.910483717918396,\n",
       "   0.9779927134513855,\n",
       "   0.8481712937355042]],\n",
       " [[0.80661541223526,\n",
       "   0.25803759694099426,\n",
       "   0.4612640142440796,\n",
       "   0.8199437856674194,\n",
       "   1.5951529741287231,\n",
       "   1.7059340476989746,\n",
       "   1.477924108505249]],\n",
       " [[1.3232253789901733,\n",
       "   0.5280614495277405,\n",
       "   0.6974382996559143,\n",
       "   1.142532229423523,\n",
       "   2.1230416297912598,\n",
       "   2.1215271949768066,\n",
       "   1.8268533945083618]],\n",
       " [[1.562026858329773,\n",
       "   0.5371406674385071,\n",
       "   0.980837345123291,\n",
       "   1.5580981969833374,\n",
       "   2.478116273880005,\n",
       "   2.433326005935669,\n",
       "   2.275474786758423]],\n",
       " [[1.7862745523452759,\n",
       "   0.7267669439315796,\n",
       "   1.1970322132110596,\n",
       "   1.8190288543701172,\n",
       "   2.7238829135894775,\n",
       "   2.4798614978790283,\n",
       "   2.2375428676605225]]]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 63)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_multi_pred_out = retrieve_from_lambda(resp)      \n",
    "y_multi_pred_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.52160013, -0.57683718, -0.53593057, -0.49511912, -0.42649588,\n",
       "        -0.35942143, -0.34173018, -0.4397223 , -0.53815252, -0.45271343,\n",
       "        -0.37354854, -0.26488113, -0.18651608, -0.19224025, -0.31746447,\n",
       "        -0.38433075, -0.30356526, -0.23604824, -0.09988704,  0.00302994,\n",
       "         0.01115496, -0.00750393, -0.16600263, -0.03220543,  0.09823962,\n",
       "         0.36003596,  0.43964979,  0.39911485,  0.28309819, -0.03286879,\n",
       "         0.20234275,  0.46264091,  0.91048372,  0.97799271,  0.84817129,\n",
       "         0.80661541,  0.2580376 ,  0.46126401,  0.81994379,  1.59515297,\n",
       "         1.70593405,  1.47792411,  1.32322538,  0.52806145,  0.6974383 ,\n",
       "         1.14253223,  2.12304163,  2.12152719,  1.82685339,  1.56202686,\n",
       "         0.53714067,  0.98083735,  1.5580982 ,  2.47811627,  2.43332601,\n",
       "         2.27547479,  1.78627455,  0.72676694,  1.19703221,  1.81902885,\n",
       "         2.72388291,  2.4798615 ,  2.23754287]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_multi_pred_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.52160007, -0.5768372 , -0.5359306 , -0.49511912, -0.42649588,\n",
       "        -0.35942143, -0.34173024, -0.4397223 , -0.53815246, -0.45271343,\n",
       "        -0.37354854, -0.26488113, -0.18651608, -0.19224025, -0.31746444,\n",
       "        -0.38433075, -0.30356523, -0.2360482 , -0.09988704,  0.00302994,\n",
       "         0.01115497, -0.00750393, -0.1660026 , -0.03220541,  0.09823963,\n",
       "         0.36003593,  0.4396498 ,  0.39911485,  0.28309825, -0.03286874,\n",
       "         0.20234275,  0.4626409 ,  0.91048384,  0.9779927 ,  0.8481713 ,\n",
       "         0.8066154 ,  0.25803754,  0.46126416,  0.81994396,  1.5951532 ,\n",
       "         1.705934  ,  1.4779243 ,  1.3232255 ,  0.52806145,  0.69743824,\n",
       "         1.1425322 ,  2.1230419 ,  2.1215272 ,  1.8268535 ,  1.5620267 ,\n",
       "         0.5371407 ,  0.9808372 ,  1.5580981 ,  2.4781163 ,  2.433326  ,\n",
       "         2.2754745 ,  1.7862746 ,  0.726767  ,  1.1970323 ,  1.8190287 ,\n",
       "         2.7238827 ,  2.4798615 ,  2.2375429 ]], dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_multi_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n"
     ]
    }
   ],
   "source": [
    "# Assert if the result of TFLite model is consistent with the TF model.\n",
    "np.testing.assert_almost_equal(y_multi_pred, y_multi_pred_out, decimal=3)\n",
    "print(\"Done. The result of TensorFlow matches the result of TensorFlow Lite.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "status code :  200\n",
      "[[[2.258720874786377, 1.2291589975357056, 0.11853042989969254, 0.07443636655807495, 2.296689748764038, 2.832331895828247, 2.181868076324463]]]\n"
     ]
    }
   ],
   "source": [
    "# prepare input\n",
    "json_list_list_x = prepare_to_lambda_future(dataset)\n",
    "# REQUEST URL_PREDICT = 'https://yl0910jrga.execute-api.us-east-2.amazonaws.com/dev/infer' \n",
    "resp = requests.post(URL_PREDICT, json=json_list_list_x)\n",
    "print(\"status code : \", resp.status_code) \n",
    "print(resp.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.25872087, 1.229159  , 0.11853043, 0.07443637, 2.29668975,\n",
       "        2.8323319 , 2.18186808]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_future_pred_out = retrieve_from_lambda(resp)      \n",
    "y_future_pred_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.2587209 , 1.2291588 , 0.11853043, 0.07443652, 2.2966897 ,\n",
       "        2.8323317 , 2.1818683 ]], dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_future_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n"
     ]
    }
   ],
   "source": [
    "# Assert if the result of TFLite model is consistent with the TF model.\n",
    "np.testing.assert_almost_equal(y_future_pred, y_future_pred_out, decimal=3)\n",
    "print(\"Done. The result of TensorFlow matches the result of TensorFlow Lite.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "260px",
    "width": "258px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "205px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
