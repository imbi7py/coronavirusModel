{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Time Series for COVID: Publish for app\n",
    "\n",
    "This notebook use multistep time serie model  (predicting number of cases future next days).\n",
    "\n",
    "It converts Tensorflow model into TensorFlow Lite to be able to use it in a Lambda fonction on AWS.\n",
    "\n",
    "After that, the lite model is tested and publish on AWS\n",
    "\n",
    "Finally, the lambda function is tested"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert model in TFlite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPORTANT TO DO manually:**\n",
    "- **Update TRAIN_SPLIT in my_helpers.model module**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data useful lib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# helper lib\n",
    "import shutil\n",
    "import os, stat\n",
    "import re\n",
    "import datetime\n",
    "import math\n",
    "\n",
    "# read json from http\n",
    "import json\n",
    "import urllib.request\n",
    "\n",
    "# read csv from http\n",
    "import io\n",
    "import requests\n",
    "\n",
    "# model lib\n",
    "import tensorflow as tf\n",
    "\n",
    "# from project\n",
    "from my_helpers.model import prepare_to_lambda, retrieve_from_lambda\n",
    "from my_helpers.model import prepare_to_lambda_future\n",
    "from my_helpers.model import create_list_past_hist, predict_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN_SPLIT = 135\n"
     ]
    }
   ],
   "source": [
    "PATH_TO_SAVE_DATA = \".\"\n",
    "PATH_DF_POS_FR = PATH_TO_SAVE_DATA + '/' + 'df_pos_fr.csv'\n",
    "PATH_DF_TEST_FR = PATH_TO_SAVE_DATA + '/' + 'df_test_fr.csv'\n",
    "PATH_JSON_METEO_FR = PATH_TO_SAVE_DATA + '/' + 'data_meteo_fr.json'\n",
    "PATH_DF_FEAT_FR = PATH_TO_SAVE_DATA + '/' + 'df_feat_fr.csv' \n",
    "PATH_GEO_DEP_FR = PATH_TO_SAVE_DATA + '/sources/geofrance/' + 'departments.csv'\n",
    "PATH_MDL_SINGLE_STEP = PATH_TO_SAVE_DATA + '/' + \"mdl_single_step_pos_fr\"\n",
    "PATH_MDL_MULTI_STEP = PATH_TO_SAVE_DATA + '/' + \"mdl_multi_step_pos_fr\"\n",
    "PATH_MDL_MULTI_TFLITE = PATH_TO_SAVE_DATA + '/' + \\\n",
    "    'serverless/tensorflow_lite_on_aws_lambda'\n",
    "PATH_MDL_MULTI_TFLITE_FILE = PATH_MDL_MULTI_TFLITE + '/' + \\\n",
    "    \"converted_model.tflite\"\n",
    "PATH_SERVERLESS = PATH_MDL_MULTI_TFLITE + '/' + 'serverless.yml'\n",
    "\n",
    "date_format = \"%Y-%m-%d\"\n",
    "\n",
    "#NB_POS_DATE_MIN_DF_FEAT = 140734 # on 13/05/2020\n",
    "NB_POS_DATE_MIN_DF_FEAT = 140227 # on 12/05/2020\n",
    "\n",
    "URL_PREDICT = 'https://yl0910jrga.execute-api.us-east-2.amazonaws.com/dev/infer'\n",
    "\n",
    "# model \n",
    "PAST_HISTORY = 14 # days used to predict next values in future\n",
    "FUTURE_TARGET = 7 # nb predict days later\n",
    "STEP = 1\n",
    "\n",
    "# plot\n",
    "NB_DAY_PLOT = FUTURE_TARGET*9\n",
    "\n",
    "# train split\n",
    "from my_helpers.model import TRAIN_SPLIT\n",
    "print(f\"TRAIN_SPLIT = {TRAIN_SPLIT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save file before update\n",
    "def clean_file(path_file_name):\n",
    "    '''\n",
    "    Clean file already traited : rename file with date\n",
    "    '''\n",
    "    try:\n",
    "        d = datetime.datetime.now()\n",
    "        str_date = '_' + d.strftime(\"%Y%m%d_%H_%M_%S\")\n",
    "       \n",
    "        res_re = re.search('\\.\\w+$', path_file_name)\n",
    "        \n",
    "        path_file_name_saved = \\\n",
    "            path_file_name[0:res_re.start()] + str_date + res_re.group(0)\n",
    "         \n",
    "        shutil.move(path_file_name, path_file_name_saved) \n",
    "        print('File {} moved!'.format(path_file_name_saved))\n",
    "    except:\n",
    "        print('File {} does not exist!'.format(path_file_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T_min</th>\n",
       "      <th>date</th>\n",
       "      <th>T_max</th>\n",
       "      <th>H_min</th>\n",
       "      <th>H_max</th>\n",
       "      <th>pos</th>\n",
       "      <th>age_pos</th>\n",
       "      <th>test</th>\n",
       "      <th>age_test</th>\n",
       "      <th>day_num</th>\n",
       "      <th>nb_cases</th>\n",
       "      <th>train</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-05-13</th>\n",
       "      <td>284.926667</td>\n",
       "      <td>2020-05-13</td>\n",
       "      <td>290.505000</td>\n",
       "      <td>64.661017</td>\n",
       "      <td>88.135593</td>\n",
       "      <td>882</td>\n",
       "      <td>60.987528</td>\n",
       "      <td>38613</td>\n",
       "      <td>55.469013</td>\n",
       "      <td>3</td>\n",
       "      <td>141109</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-14</th>\n",
       "      <td>285.050000</td>\n",
       "      <td>2020-05-14</td>\n",
       "      <td>290.963333</td>\n",
       "      <td>59.406780</td>\n",
       "      <td>84.847458</td>\n",
       "      <td>981</td>\n",
       "      <td>60.434251</td>\n",
       "      <td>41396</td>\n",
       "      <td>54.810127</td>\n",
       "      <td>4</td>\n",
       "      <td>142090</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-15</th>\n",
       "      <td>285.308333</td>\n",
       "      <td>2020-05-15</td>\n",
       "      <td>291.920000</td>\n",
       "      <td>57.372881</td>\n",
       "      <td>82.966102</td>\n",
       "      <td>1031</td>\n",
       "      <td>59.838991</td>\n",
       "      <td>46836</td>\n",
       "      <td>54.322679</td>\n",
       "      <td>5</td>\n",
       "      <td>143121</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-16</th>\n",
       "      <td>284.956667</td>\n",
       "      <td>2020-05-16</td>\n",
       "      <td>293.500000</td>\n",
       "      <td>53.741379</td>\n",
       "      <td>86.534483</td>\n",
       "      <td>291</td>\n",
       "      <td>60.158076</td>\n",
       "      <td>16094</td>\n",
       "      <td>54.354356</td>\n",
       "      <td>6</td>\n",
       "      <td>143412</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-17</th>\n",
       "      <td>285.598333</td>\n",
       "      <td>2020-05-17</td>\n",
       "      <td>294.446667</td>\n",
       "      <td>49.879310</td>\n",
       "      <td>85.500000</td>\n",
       "      <td>139</td>\n",
       "      <td>61.568345</td>\n",
       "      <td>6245</td>\n",
       "      <td>58.054604</td>\n",
       "      <td>0</td>\n",
       "      <td>143551</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-22</th>\n",
       "      <td>288.068333</td>\n",
       "      <td>2020-10-22</td>\n",
       "      <td>293.946667</td>\n",
       "      <td>66.254237</td>\n",
       "      <td>90.338983</td>\n",
       "      <td>48940</td>\n",
       "      <td>47.908214</td>\n",
       "      <td>253252</td>\n",
       "      <td>46.256278</td>\n",
       "      <td>4</td>\n",
       "      <td>1099014</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-23</th>\n",
       "      <td>287.036441</td>\n",
       "      <td>2020-10-23</td>\n",
       "      <td>292.078814</td>\n",
       "      <td>70.017241</td>\n",
       "      <td>92.896552</td>\n",
       "      <td>52533</td>\n",
       "      <td>48.007462</td>\n",
       "      <td>277455</td>\n",
       "      <td>46.673734</td>\n",
       "      <td>5</td>\n",
       "      <td>1151547</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-24</th>\n",
       "      <td>286.104237</td>\n",
       "      <td>2020-10-24</td>\n",
       "      <td>292.195763</td>\n",
       "      <td>66.327586</td>\n",
       "      <td>91.137931</td>\n",
       "      <td>23577</td>\n",
       "      <td>47.540993</td>\n",
       "      <td>120734</td>\n",
       "      <td>46.430161</td>\n",
       "      <td>6</td>\n",
       "      <td>1175124</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-25</th>\n",
       "      <td>284.972034</td>\n",
       "      <td>2020-10-25</td>\n",
       "      <td>291.231356</td>\n",
       "      <td>65.655172</td>\n",
       "      <td>90.327586</td>\n",
       "      <td>6774</td>\n",
       "      <td>49.660614</td>\n",
       "      <td>32030</td>\n",
       "      <td>47.858914</td>\n",
       "      <td>0</td>\n",
       "      <td>1181898</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-26</th>\n",
       "      <td>284.690000</td>\n",
       "      <td>2020-10-26</td>\n",
       "      <td>289.685000</td>\n",
       "      <td>67.067797</td>\n",
       "      <td>90.491525</td>\n",
       "      <td>57160</td>\n",
       "      <td>48.415308</td>\n",
       "      <td>272383</td>\n",
       "      <td>47.673434</td>\n",
       "      <td>1</td>\n",
       "      <td>1239058</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>167 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 T_min        date       T_max      H_min      H_max    pos  \\\n",
       "date                                                                          \n",
       "2020-05-13  284.926667  2020-05-13  290.505000  64.661017  88.135593    882   \n",
       "2020-05-14  285.050000  2020-05-14  290.963333  59.406780  84.847458    981   \n",
       "2020-05-15  285.308333  2020-05-15  291.920000  57.372881  82.966102   1031   \n",
       "2020-05-16  284.956667  2020-05-16  293.500000  53.741379  86.534483    291   \n",
       "2020-05-17  285.598333  2020-05-17  294.446667  49.879310  85.500000    139   \n",
       "...                ...         ...         ...        ...        ...    ...   \n",
       "2020-10-22  288.068333  2020-10-22  293.946667  66.254237  90.338983  48940   \n",
       "2020-10-23  287.036441  2020-10-23  292.078814  70.017241  92.896552  52533   \n",
       "2020-10-24  286.104237  2020-10-24  292.195763  66.327586  91.137931  23577   \n",
       "2020-10-25  284.972034  2020-10-25  291.231356  65.655172  90.327586   6774   \n",
       "2020-10-26  284.690000  2020-10-26  289.685000  67.067797  90.491525  57160   \n",
       "\n",
       "              age_pos    test   age_test  day_num  nb_cases  train  \n",
       "date                                                                \n",
       "2020-05-13  60.987528   38613  55.469013        3    141109   True  \n",
       "2020-05-14  60.434251   41396  54.810127        4    142090   True  \n",
       "2020-05-15  59.838991   46836  54.322679        5    143121   True  \n",
       "2020-05-16  60.158076   16094  54.354356        6    143412   True  \n",
       "2020-05-17  61.568345    6245  58.054604        0    143551   True  \n",
       "...               ...     ...        ...      ...       ...    ...  \n",
       "2020-10-22  47.908214  253252  46.256278        4   1099014  False  \n",
       "2020-10-23  48.007462  277455  46.673734        5   1151547  False  \n",
       "2020-10-24  47.540993  120734  46.430161        6   1175124  False  \n",
       "2020-10-25  49.660614   32030  47.858914        0   1181898  False  \n",
       "2020-10-26  48.415308  272383  47.673434        1   1239058  False  \n",
       "\n",
       "[167 rows x 12 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_feat_fr = pd.read_csv(PATH_DF_FEAT_FR)\n",
    "df_feat_fr.index = df_feat_fr[\"date\"]\n",
    "df_feat_fr[\"train\"] = [True if I <= TRAIN_SPLIT else False \\\n",
    "                       for I in range(df_feat_fr.shape[0])]\n",
    "df_feat_fr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prepare features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T_min</th>\n",
       "      <th>T_max</th>\n",
       "      <th>H_min</th>\n",
       "      <th>H_max</th>\n",
       "      <th>pos</th>\n",
       "      <th>test</th>\n",
       "      <th>day_num</th>\n",
       "      <th>age_pos</th>\n",
       "      <th>age_test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-05-13</th>\n",
       "      <td>284.926667</td>\n",
       "      <td>290.505000</td>\n",
       "      <td>64.661017</td>\n",
       "      <td>88.135593</td>\n",
       "      <td>882</td>\n",
       "      <td>38613</td>\n",
       "      <td>3</td>\n",
       "      <td>60.987528</td>\n",
       "      <td>55.469013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-14</th>\n",
       "      <td>285.050000</td>\n",
       "      <td>290.963333</td>\n",
       "      <td>59.406780</td>\n",
       "      <td>84.847458</td>\n",
       "      <td>981</td>\n",
       "      <td>41396</td>\n",
       "      <td>4</td>\n",
       "      <td>60.434251</td>\n",
       "      <td>54.810127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-15</th>\n",
       "      <td>285.308333</td>\n",
       "      <td>291.920000</td>\n",
       "      <td>57.372881</td>\n",
       "      <td>82.966102</td>\n",
       "      <td>1031</td>\n",
       "      <td>46836</td>\n",
       "      <td>5</td>\n",
       "      <td>59.838991</td>\n",
       "      <td>54.322679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-16</th>\n",
       "      <td>284.956667</td>\n",
       "      <td>293.500000</td>\n",
       "      <td>53.741379</td>\n",
       "      <td>86.534483</td>\n",
       "      <td>291</td>\n",
       "      <td>16094</td>\n",
       "      <td>6</td>\n",
       "      <td>60.158076</td>\n",
       "      <td>54.354356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-17</th>\n",
       "      <td>285.598333</td>\n",
       "      <td>294.446667</td>\n",
       "      <td>49.879310</td>\n",
       "      <td>85.500000</td>\n",
       "      <td>139</td>\n",
       "      <td>6245</td>\n",
       "      <td>0</td>\n",
       "      <td>61.568345</td>\n",
       "      <td>58.054604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-22</th>\n",
       "      <td>288.068333</td>\n",
       "      <td>293.946667</td>\n",
       "      <td>66.254237</td>\n",
       "      <td>90.338983</td>\n",
       "      <td>48940</td>\n",
       "      <td>253252</td>\n",
       "      <td>4</td>\n",
       "      <td>47.908214</td>\n",
       "      <td>46.256278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-23</th>\n",
       "      <td>287.036441</td>\n",
       "      <td>292.078814</td>\n",
       "      <td>70.017241</td>\n",
       "      <td>92.896552</td>\n",
       "      <td>52533</td>\n",
       "      <td>277455</td>\n",
       "      <td>5</td>\n",
       "      <td>48.007462</td>\n",
       "      <td>46.673734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-24</th>\n",
       "      <td>286.104237</td>\n",
       "      <td>292.195763</td>\n",
       "      <td>66.327586</td>\n",
       "      <td>91.137931</td>\n",
       "      <td>23577</td>\n",
       "      <td>120734</td>\n",
       "      <td>6</td>\n",
       "      <td>47.540993</td>\n",
       "      <td>46.430161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-25</th>\n",
       "      <td>284.972034</td>\n",
       "      <td>291.231356</td>\n",
       "      <td>65.655172</td>\n",
       "      <td>90.327586</td>\n",
       "      <td>6774</td>\n",
       "      <td>32030</td>\n",
       "      <td>0</td>\n",
       "      <td>49.660614</td>\n",
       "      <td>47.858914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-26</th>\n",
       "      <td>284.690000</td>\n",
       "      <td>289.685000</td>\n",
       "      <td>67.067797</td>\n",
       "      <td>90.491525</td>\n",
       "      <td>57160</td>\n",
       "      <td>272383</td>\n",
       "      <td>1</td>\n",
       "      <td>48.415308</td>\n",
       "      <td>47.673434</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>167 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 T_min       T_max      H_min      H_max    pos    test  \\\n",
       "date                                                                      \n",
       "2020-05-13  284.926667  290.505000  64.661017  88.135593    882   38613   \n",
       "2020-05-14  285.050000  290.963333  59.406780  84.847458    981   41396   \n",
       "2020-05-15  285.308333  291.920000  57.372881  82.966102   1031   46836   \n",
       "2020-05-16  284.956667  293.500000  53.741379  86.534483    291   16094   \n",
       "2020-05-17  285.598333  294.446667  49.879310  85.500000    139    6245   \n",
       "...                ...         ...        ...        ...    ...     ...   \n",
       "2020-10-22  288.068333  293.946667  66.254237  90.338983  48940  253252   \n",
       "2020-10-23  287.036441  292.078814  70.017241  92.896552  52533  277455   \n",
       "2020-10-24  286.104237  292.195763  66.327586  91.137931  23577  120734   \n",
       "2020-10-25  284.972034  291.231356  65.655172  90.327586   6774   32030   \n",
       "2020-10-26  284.690000  289.685000  67.067797  90.491525  57160  272383   \n",
       "\n",
       "            day_num    age_pos   age_test  \n",
       "date                                       \n",
       "2020-05-13        3  60.987528  55.469013  \n",
       "2020-05-14        4  60.434251  54.810127  \n",
       "2020-05-15        5  59.838991  54.322679  \n",
       "2020-05-16        6  60.158076  54.354356  \n",
       "2020-05-17        0  61.568345  58.054604  \n",
       "...             ...        ...        ...  \n",
       "2020-10-22        4  47.908214  46.256278  \n",
       "2020-10-23        5  48.007462  46.673734  \n",
       "2020-10-24        6  47.540993  46.430161  \n",
       "2020-10-25        0  49.660614  47.858914  \n",
       "2020-10-26        1  48.415308  47.673434  \n",
       "\n",
       "[167 rows x 9 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = df_feat_fr.copy().filter(items=['T_min', 'T_max', 'H_min',\n",
    "                                           'H_max', 'pos', 'test', 'day_num',\n",
    "                                          'age_pos', 'age_test'])\n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = features.values\n",
    "data_mean = dataset[:TRAIN_SPLIT].mean(axis=0)\n",
    "data_std = dataset[:TRAIN_SPLIT].std(axis=0)\n",
    "dataset = (dataset-data_mean)/data_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PAST_HISTORY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.recurrent_v2.LSTM object at 0x63c094f90> and <tensorflow.python.keras.layers.core.Dropout object at 0x139c9bbd0>).\n",
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x63c10f490> and <tensorflow.python.keras.layers.core.Dense object at 0x63c119a50>).\n",
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x63c10f490> and <tensorflow.python.keras.layers.core.Dropout object at 0x139c9bbd0>).\n",
      "CPU times: user 2.45 s, sys: 173 ms, total: 2.62 s\n",
      "Wall time: 3.02 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# reload best model\n",
    "multi_step_model = tf.keras.models.load_model(PATH_MDL_MULTI_STEP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf.float32"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_step_model.inputs[0].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/envs/coronavirusModel/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From /anaconda3/envs/coronavirusModel/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: ./keras_lstm/assets\n"
     ]
    }
   ],
   "source": [
    "run_model = tf.function(lambda x: multi_step_model(x))\n",
    "# This is important, let's fix the input size.\n",
    "INPUT_SIZE = dataset.shape[1]\n",
    "concrete_func = run_model.get_concrete_function(\n",
    "    tf.TensorSpec([1, PAST_HISTORY, INPUT_SIZE],\n",
    "                  multi_step_model.inputs[0].dtype))\n",
    "\n",
    "# model directory.\n",
    "MODEL_DIR = PATH_TO_SAVE_DATA + \"/\" + \"keras_lstm\"\n",
    "multi_step_model.save(MODEL_DIR, save_format=\"tf\", signatures=concrete_func)\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(MODEL_DIR)\n",
    "\n",
    "'''converter.target_spec.supported_ops = [\n",
    "  tf.lite.OpsSet.TFLITE_BUILTINS, # enable TensorFlow Lite ops.\n",
    "  tf.lite.OpsSet.SELECT_TF_OPS # enable TensorFlow ops.\n",
    "]\n",
    "converter.allow_custom_ops=True'''\n",
    "\n",
    "tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model TFlite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ./serverless/tensorflow_lite_on_aws_lambda/converted_model_20201030_17_33_58.tflite moved!\n"
     ]
    }
   ],
   "source": [
    "clean_file(PATH_MDL_MULTI_TFLITE_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6104"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open(PATH_MDL_MULTI_TFLITE_FILE, \"wb\").write(tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test converted model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict with TF model (not-converted one)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Past days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[58 - 72]\n",
      "[65 - 79]\n",
      "[72 - 86]\n",
      "[79 - 93]\n",
      "[86 - 100]\n",
      "[93 - 107]\n",
      "[100 - 114]\n",
      "[107 - 121]\n",
      "[114 - 128]\n",
      "9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  814.1582 ,   583.9282 ,   606.40186,   814.5974 ,  1025.219  ,\n",
       "         1217.3073 ,  1303.9923 ,  1047.2645 ,   749.4304 ,  1179.5789 ,\n",
       "         1440.1638 ,  1488.9644 ,  1699.5714 ,  1812.4594 ,  1557.5139 ,\n",
       "         1246.2732 ,  1179.1752 ,  1793.6415 ,  2323.6118 ,  2527.147  ,\n",
       "         2529.7927 ,  2188.1914 ,  1579.2222 ,  2183.4146 ,  3467.8218 ,\n",
       "         3882.2388 ,  3890.2764 ,  4097.167  ,  3720.858  ,  2534.9634 ,\n",
       "         2686.615  ,  4838.0923 ,  5727.835  ,  5415.9976 ,  5833.218  ,\n",
       "         5480.083  ,  2745.1045 ,  2892.1353 ,  6756.036  ,  8333.597  ,\n",
       "         7592.1436 ,  8443.741  ,  7841.1523 ,  3621.1506 ,  3887.908  ,\n",
       "        10062.342  , 11882.219  ,  9718.192  , 11525.329  ,  8651.092  ,\n",
       "         3160.4739 ,  4677.614  , 11304.128  , 12989.707  , 10908.019  ,\n",
       "        12652.731  ,  8159.621  ,  4238.619  ,  5153.3184 , 10712.284  ,\n",
       "        11636.399  ,  9384.854  , 11557.597  ]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TENSORFLOW MODEL :\n",
    "# prepare list of past histories\n",
    "list_x = create_list_past_hist(dataset)\n",
    "# predict\n",
    "y_multi_pred = predict_list(list_x, multi_step_model)\n",
    "# convert in positive cases\n",
    "y_pos_pred = (y_multi_pred * data_std[4]) + data_mean[4] \n",
    "y_pos_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Future days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data : very last days\n",
    "x_for_future = np.array([dataset[-PAST_HISTORY:,:]]) \n",
    "# predict next days\n",
    "y_future_pred = multi_step_model.predict(x_for_future)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict with TFlite & Compare "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Past days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n",
      "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n",
      "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n",
      "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n",
      "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n",
      "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n",
      "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n",
      "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n",
      "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n"
     ]
    }
   ],
   "source": [
    "# CONVERTED LITE MODEL\n",
    "# load \n",
    "interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
    "\n",
    "# Run the model with TensorFlow Lite\n",
    "interpreter.allocate_tensors()\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# check if same results \n",
    "for x_multi in list_x:\n",
    "    # predict with tensorflow model\n",
    "    expected = multi_step_model.predict(x_multi)\n",
    "    # predict with TFlite model\n",
    "    interpreter.set_tensor(input_details[0][\"index\"], \n",
    "                           x_multi.astype(np.float32))\n",
    "    interpreter.invoke()\n",
    "    result = interpreter.get_tensor(output_details[0][\"index\"])\n",
    "\n",
    "    # Assert if the result of TFLite model is consistent with the TF model.\n",
    "    np.testing.assert_almost_equal(expected, result, decimal=3)\n",
    "    print(\"Done. The result of TensorFlow matches the result of TensorFlow Lite.\")\n",
    "\n",
    "    # Please note: TfLite fused Lstm kernel is stateful, so we need to reset\n",
    "    # the states.\n",
    "    # Clean up internal states.\n",
    "    interpreter.reset_all_variables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reload Tlite model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path=PATH_MDL_MULTI_TFLITE_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./serverless/tensorflow_lite_on_aws_lambda/converted_model.tflite'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH_MDL_MULTI_TFLITE_FILE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict reloaded model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Past days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n",
      "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n",
      "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n",
      "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n",
      "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n",
      "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n",
      "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n",
      "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n",
      "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n"
     ]
    }
   ],
   "source": [
    "# Run the model with TensorFlow Lite\n",
    "interpreter.allocate_tensors()\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# check if same results \n",
    "for x_multi in list_x:\n",
    "    \n",
    "    expected = multi_step_model.predict(x_multi)\n",
    "    \n",
    "    interpreter.set_tensor(input_details[0][\"index\"], \n",
    "                           x_multi.astype(np.float32))\n",
    "    interpreter.invoke()\n",
    "    result = interpreter.get_tensor(output_details[0][\"index\"])\n",
    "\n",
    "    # Assert if the result of TFLite model is consistent with the TF model.\n",
    "    np.testing.assert_almost_equal(expected, result, decimal=3)\n",
    "    print(\"Done. The result of TensorFlow matches the result of TensorFlow Lite.\")\n",
    "\n",
    "    # Please note: TfLite fused Lstm kernel is stateful, so we need to reset\n",
    "    # the states.\n",
    "    # Clean up internal states.\n",
    "    interpreter.reset_all_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 14, 9)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_multi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update API lambda AWS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API lambda simulate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Past days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(167, 9)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[58 - 72]\n",
      "[65 - 79]\n",
      "[72 - 86]\n",
      "[79 - 93]\n",
      "[86 - 100]\n",
      "[93 - 107]\n",
      "[100 - 114]\n",
      "[107 - 121]\n",
      "[114 - 128]\n"
     ]
    }
   ],
   "source": [
    "json_list_list_x = prepare_to_lambda(dataset)\n",
    "# simulate input to lambda (double dumps ? why ? i don't know yet)\n",
    "json_list_list_x = json.dumps(json_list_list_x)\n",
    "# simulate lambda\n",
    "\n",
    "event = {\"body\": json_list_list_x}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT : nb. arrays : 9 / arrays shape: (1, 14, 9)\n",
      "OUTPUT : nb. arrays : 9 / arrays shape in list: (1, 7)\n"
     ]
    }
   ],
   "source": [
    "# lambda code (file ./serverless/tensorflow-lite-on-aws-lambda/handler.py)\n",
    "from serverless.tensorflow_lite_on_aws_lambda.handler import predict\n",
    "context = None\n",
    "response = predict(event, context)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 63)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve from lambda in App code\n",
    "# input : response\n",
    "y_multi_pred_out = retrieve_from_lambda(response)      \n",
    "y_multi_pred_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-5.1732117e-01, -5.7452375e-01, -5.6893998e-01, -5.1721203e-01,\n",
       "        -4.6488130e-01, -4.1715536e-01, -3.9561772e-01, -4.5940390e-01,\n",
       "        -5.3340334e-01, -4.2652929e-01, -3.6178476e-01, -3.4965986e-01,\n",
       "        -2.9733273e-01, -2.6928478e-01, -3.3262813e-01, -4.0995851e-01,\n",
       "        -4.2662960e-01, -2.7396023e-01, -1.4228460e-01, -9.1714621e-02,\n",
       "        -9.1057241e-02, -1.7593101e-01, -3.2723454e-01, -1.7711782e-01,\n",
       "         1.4200398e-01,  2.4496943e-01,  2.4696645e-01,  2.9837018e-01,\n",
       "         2.0487297e-01, -8.9772537e-02, -5.2093413e-02,  4.8245931e-01,\n",
       "         7.0352340e-01,  6.2604475e-01,  7.2970659e-01,  6.4196730e-01,\n",
       "        -3.7561230e-02, -1.0301718e-03,  9.5898873e-01,  1.3509469e+00,\n",
       "         1.1667266e+00,  1.3783133e+00,  1.2285950e+00,  1.8009989e-01,\n",
       "         2.4637797e-01,  1.7804682e+00,  2.2326322e+00,  1.6949615e+00,\n",
       "         2.1439600e+00,  1.4298314e+00,  6.5640852e-02,  4.4258708e-01,\n",
       "         2.0890007e+00,  2.5077970e+00,  1.9905839e+00,  2.4240725e+00,\n",
       "         1.3077213e+00,  3.3351520e-01,  5.6077993e-01,  1.9419520e+00,\n",
       "         2.1715562e+00,  1.6121405e+00,  2.1519771e+00]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_multi_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-5.17321110e-01, -5.74523807e-01, -5.68940043e-01,\n",
       "        -5.17212033e-01, -4.64881212e-01, -4.17155355e-01,\n",
       "        -3.95617664e-01, -4.59403932e-01, -5.33403337e-01,\n",
       "        -4.26529258e-01, -3.61784786e-01, -3.49659920e-01,\n",
       "        -2.97332764e-01, -2.69284815e-01, -3.32628131e-01,\n",
       "        -4.09958512e-01, -4.26629603e-01, -2.73960263e-01,\n",
       "        -1.42284647e-01, -9.17146355e-02, -9.10572708e-02,\n",
       "        -1.75930962e-01, -3.27234447e-01, -1.77117839e-01,\n",
       "         1.42003983e-01,  2.44969487e-01,  2.46966541e-01,\n",
       "         2.98370153e-01,  2.04872906e-01, -8.97726566e-02,\n",
       "        -5.20933904e-02,  4.82459396e-01,  7.03523457e-01,\n",
       "         6.26044750e-01,  7.29706585e-01,  6.41967118e-01,\n",
       "        -3.75612527e-02, -1.03015546e-03,  9.58988726e-01,\n",
       "         1.35094690e+00,  1.16672659e+00,  1.37831330e+00,\n",
       "         1.22859478e+00,  1.80100009e-01,  2.46377558e-01,\n",
       "         1.78046775e+00,  2.23263192e+00,  1.69496131e+00,\n",
       "         2.14395952e+00,  1.42983115e+00,  6.56409860e-02,\n",
       "         4.42586601e-01,  2.08900023e+00,  2.50779700e+00,\n",
       "         1.99058378e+00,  2.42407203e+00,  1.30772090e+00,\n",
       "         3.33514929e-01,  5.60779989e-01,  1.94195199e+00,\n",
       "         2.17155623e+00,  1.61214030e+00,  2.15197706e+00]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_multi_pred_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n"
     ]
    }
   ],
   "source": [
    "# Assert if the result of TFLite model is consistent with the TF model.\n",
    "np.testing.assert_almost_equal(y_multi_pred, y_multi_pred_out, decimal=3)\n",
    "print(\"Done. The result of TensorFlow matches the result of TensorFlow Lite.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Future days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT : nb. arrays : 1 / arrays shape: (1, 14, 9)\n",
      "OUTPUT : nb. arrays : 1 / arrays shape in list: (1, 7)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 7)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare data to lambda (future)\n",
    "json_list_list_x = prepare_to_lambda_future(dataset)\n",
    "\n",
    "# simulate lambda\n",
    "json_list_list_x = json.dumps(json_list_list_x) # dumps again : I dont know why\n",
    "event = {\"body\": json_list_list_x}\n",
    "context = None\n",
    "response = predict(event, context)\n",
    "y_future_pred_out = retrieve_from_lambda(response)      \n",
    "y_future_pred_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.07842183, 2.39811206, 6.6593318 , 5.35568762, 2.04537964,\n",
       "        4.28097916, 7.50129271]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_future_pred_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.0784218, 2.398112 , 6.659332 , 5.3556876, 2.0453794, 4.2809796,\n",
       "        7.501292 ]], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_future_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n"
     ]
    }
   ],
   "source": [
    "# Assert if the result of TFLite model is consistent with the TF model.\n",
    "np.testing.assert_almost_equal(y_future_pred, y_future_pred_out, decimal=3)\n",
    "print(\"Done. The result of TensorFlow matches the result of TensorFlow Lite.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update AWS Lambda with new model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part does:\n",
    "- Go to : ./serverless//tensorflow-lite-on-aws-lambda\n",
    "    \n",
    "- Execute : sls deploy -v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#!/bin/bash\\nexport PATH=\"/usr/local/bin:$PATH\"\\ncd ./serverless/tensorflow_lite_on_aws_lambda\\nserverless deploy -v'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str_exe = '#!/bin/bash\\n' + \\\n",
    "    'export PATH=\"/usr/local/bin:$PATH\"\\n' + \\\n",
    "    f'cd {PATH_MDL_MULTI_TFLITE}\\n' + \\\n",
    "    'serverless deploy -v'\n",
    "str_exe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "open('deploy_serverless.sh', \"w\").write(str_exe)\n",
    "os.chmod('deploy_serverless.sh', stat.S_IRWXU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/bin/bash\r\n",
      "export PATH=\"/usr/local/bin:$PATH\"\r\n",
      "cd ./serverless/tensorflow_lite_on_aws_lambda\r\n",
      "serverless deploy -v"
     ]
    }
   ],
   "source": [
    "!cat ./deploy_serverless.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serverless: Generated requirements from /Users/gregory/Documents/CloudStationSinchon/Applications/python/CoronaVirus/code/coronavirusModel/serverless/tensorflow_lite_on_aws_lambda/requirements.txt in /Users/gregory/Documents/CloudStationSinchon/Applications/python/CoronaVirus/code/coronavirusModel/serverless/tensorflow_lite_on_aws_lambda/.serverless/requirements.txt...\n",
      "Serverless: Using static cache of requirements found at /Users/gregory/Library/Caches/serverless-python-requirements/ef4e42eb03bbad46f74fee99a3c01f994e8119e7a557f947779093ab37b248d3_slspyc ...\n",
      "Serverless: Packaging service...\n",
      "Serverless: Excluding development dependencies...\n",
      "Serverless: Injecting required Python packages to package...\n",
      "Serverless: Uploading CloudFormation file to S3...\n",
      "Serverless: Uploading artifacts...\n",
      "Serverless: Uploading service tensorflow-lite-on-aws-lambda.zip file to S3 (18.4 MB)...\n",
      "Serverless: Validating template...\n",
      "Serverless: Updating Stack...\n",
      "Serverless: Checking Stack update progress...\n",
      "CloudFormation - UPDATE_IN_PROGRESS - AWS::CloudFormation::Stack - tensorflow-lite-on-aws-lambda-dev\n",
      "CloudFormation - UPDATE_IN_PROGRESS - AWS::Lambda::Function - PredictLambdaFunction\n",
      "CloudFormation - UPDATE_COMPLETE - AWS::Lambda::Function - PredictLambdaFunction\n",
      "CloudFormation - CREATE_IN_PROGRESS - AWS::Lambda::Version - PredictLambdaVersionfZPR6ihexVy5F4K7qfaWyE8U3GOaa1S33thT9MjYeo\n",
      "CloudFormation - CREATE_IN_PROGRESS - AWS::Lambda::Version - PredictLambdaVersionfZPR6ihexVy5F4K7qfaWyE8U3GOaa1S33thT9MjYeo\n",
      "CloudFormation - CREATE_COMPLETE - AWS::Lambda::Version - PredictLambdaVersionfZPR6ihexVy5F4K7qfaWyE8U3GOaa1S33thT9MjYeo\n",
      "CloudFormation - CREATE_IN_PROGRESS - AWS::ApiGateway::Deployment - ApiGatewayDeployment1604052133085\n",
      "CloudFormation - CREATE_IN_PROGRESS - AWS::ApiGateway::Deployment - ApiGatewayDeployment1604052133085\n",
      "CloudFormation - CREATE_COMPLETE - AWS::ApiGateway::Deployment - ApiGatewayDeployment1604052133085\n",
      "CloudFormation - UPDATE_COMPLETE_CLEANUP_IN_PROGRESS - AWS::CloudFormation::Stack - tensorflow-lite-on-aws-lambda-dev\n",
      "CloudFormation - DELETE_IN_PROGRESS - AWS::ApiGateway::Deployment - ApiGatewayDeployment1602727964559\n",
      "CloudFormation - DELETE_SKIPPED - AWS::Lambda::Version - PredictLambdaVersionanKkLwwZlyJLrT6FdTth8HXCizBhd5aTHaxue1skPVI\n",
      "CloudFormation - DELETE_COMPLETE - AWS::ApiGateway::Deployment - ApiGatewayDeployment1602727964559\n",
      "CloudFormation - UPDATE_COMPLETE - AWS::CloudFormation::Stack - tensorflow-lite-on-aws-lambda-dev\n",
      "Serverless: Stack update finished...\n",
      "Service Information\n",
      "service: tensorflow-lite-on-aws-lambda\n",
      "stage: dev\n",
      "region: us-east-2\n",
      "stack: tensorflow-lite-on-aws-lambda-dev\n",
      "resources: 11\n",
      "api keys:\n",
      "  None\n",
      "endpoints:\n",
      "  POST - https://yl0910jrga.execute-api.us-east-2.amazonaws.com/dev/infer\n",
      "functions:\n",
      "  predict: tensorflow-lite-on-aws-lambda-dev-predict\n",
      "layers:\n",
      "  None\n",
      "\n",
      "Stack Outputs\n",
      "PredictLambdaFunctionQualifiedArn: arn:aws:lambda:us-east-2:324466407431:function:tensorflow-lite-on-aws-lambda-dev-predict:11\n",
      "ServiceEndpoint: https://yl0910jrga.execute-api.us-east-2.amazonaws.com/dev\n",
      "ServerlessDeploymentBucketName: tensorflow-lite-on-aws-l-serverlessdeploymentbuck-1vuz80v36l59q\n",
      "\n",
      "Serverless: Removing old service artifacts from S3...\n",
      "\n",
      "********************************************************************************\n",
      "Serverless: Announcing Metrics, CI/CD, Secrets and more built into Serverless Framework. Run \"serverless login\" to activate for free..\n",
      "********************************************************************************\n",
      "\n",
      "\n",
      "\n",
      "   ╭───────────────────────────────────────╮\n",
      "   │                                       │\n",
      "   │   Update available 1.79.0 → 2.7.0     │\n",
      "   │   Run npm i -g serverless to update   │\n",
      "   │                                       │\n",
      "   ╰───────────────────────────────────────╯\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!./deploy_serverless.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API AWS real Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Past days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[58 - 72]\n",
      "[65 - 79]\n",
      "[72 - 86]\n",
      "[79 - 93]\n",
      "[86 - 100]\n",
      "[93 - 107]\n",
      "[100 - 114]\n",
      "[107 - 121]\n",
      "[114 - 128]\n",
      "status code :  200\n",
      "[[[-0.5173211097717285, -0.5745238065719604, -0.5689399838447571, -0.5172120332717896, -0.4648812413215637, -0.417155385017395, -0.39561766386032104]], [[-0.4594038724899292, -0.5334033370018005, -0.42652931809425354, -0.36178475618362427, -0.34965986013412476, -0.2973327338695526, -0.26928478479385376]], [[-0.3326281011104584, -0.40995851159095764, -0.42662960290908813, -0.2739602327346802, -0.14228461682796478, -0.09171462059020996, -0.09105727076530457]], [[-0.1759309470653534, -0.3272344470024109, -0.17711782455444336, 0.14200395345687866, 0.2449694275856018, 0.24696645140647888, 0.2983701229095459]], [[0.2048729956150055, -0.08977252244949341, -0.052093494683504105, 0.48245933651924133, 0.7035234570503235, 0.626044750213623, 0.7297065854072571]], [[0.6419671773910522, -0.037561241537332535, -0.001030157320201397, 0.9589887857437134, 1.3509469032287598, 1.1667264699935913, 1.3783133029937744]], [[1.2285946607589722, 0.1800996959209442, 0.24637773633003235, 1.7804677486419678, 2.2326319217681885, 1.694961428642273, 2.1439597606658936]], [[1.4298312664031982, 0.06564059853553772, 0.44258689880371094, 2.089000940322876, 2.5077974796295166, 1.9905842542648315, 2.424072504043579]], [[1.3077208995819092, 0.3335150480270386, 0.5607801079750061, 1.9419519901275635, 2.171556234359741, 1.6121405363082886, 2.151977062225342]]]\n"
     ]
    }
   ],
   "source": [
    "# prepare input\n",
    "json_list_list_x = prepare_to_lambda(dataset)\n",
    "# REQUEST\n",
    "resp = requests.post(URL_PREDICT, json=json_list_list_x)\n",
    "print(\"status code : \", resp.status_code) \n",
    "print(resp.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23764"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(json_list_list_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[-0.5173211097717285,\n",
       "   -0.5745238065719604,\n",
       "   -0.5689399838447571,\n",
       "   -0.5172120332717896,\n",
       "   -0.4648812413215637,\n",
       "   -0.417155385017395,\n",
       "   -0.39561766386032104]],\n",
       " [[-0.4594038724899292,\n",
       "   -0.5334033370018005,\n",
       "   -0.42652931809425354,\n",
       "   -0.36178475618362427,\n",
       "   -0.34965986013412476,\n",
       "   -0.2973327338695526,\n",
       "   -0.26928478479385376]],\n",
       " [[-0.3326281011104584,\n",
       "   -0.40995851159095764,\n",
       "   -0.42662960290908813,\n",
       "   -0.2739602327346802,\n",
       "   -0.14228461682796478,\n",
       "   -0.09171462059020996,\n",
       "   -0.09105727076530457]],\n",
       " [[-0.1759309470653534,\n",
       "   -0.3272344470024109,\n",
       "   -0.17711782455444336,\n",
       "   0.14200395345687866,\n",
       "   0.2449694275856018,\n",
       "   0.24696645140647888,\n",
       "   0.2983701229095459]],\n",
       " [[0.2048729956150055,\n",
       "   -0.08977252244949341,\n",
       "   -0.052093494683504105,\n",
       "   0.48245933651924133,\n",
       "   0.7035234570503235,\n",
       "   0.626044750213623,\n",
       "   0.7297065854072571]],\n",
       " [[0.6419671773910522,\n",
       "   -0.037561241537332535,\n",
       "   -0.001030157320201397,\n",
       "   0.9589887857437134,\n",
       "   1.3509469032287598,\n",
       "   1.1667264699935913,\n",
       "   1.3783133029937744]],\n",
       " [[1.2285946607589722,\n",
       "   0.1800996959209442,\n",
       "   0.24637773633003235,\n",
       "   1.7804677486419678,\n",
       "   2.2326319217681885,\n",
       "   1.694961428642273,\n",
       "   2.1439597606658936]],\n",
       " [[1.4298312664031982,\n",
       "   0.06564059853553772,\n",
       "   0.44258689880371094,\n",
       "   2.089000940322876,\n",
       "   2.5077974796295166,\n",
       "   1.9905842542648315,\n",
       "   2.424072504043579]],\n",
       " [[1.3077208995819092,\n",
       "   0.3335150480270386,\n",
       "   0.5607801079750061,\n",
       "   1.9419519901275635,\n",
       "   2.171556234359741,\n",
       "   1.6121405363082886,\n",
       "   2.151977062225342]]]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 63)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_multi_pred_out = retrieve_from_lambda(resp)      \n",
    "y_multi_pred_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-5.17321110e-01, -5.74523807e-01, -5.68939984e-01,\n",
       "        -5.17212033e-01, -4.64881241e-01, -4.17155385e-01,\n",
       "        -3.95617664e-01, -4.59403872e-01, -5.33403337e-01,\n",
       "        -4.26529318e-01, -3.61784756e-01, -3.49659860e-01,\n",
       "        -2.97332734e-01, -2.69284785e-01, -3.32628101e-01,\n",
       "        -4.09958512e-01, -4.26629603e-01, -2.73960233e-01,\n",
       "        -1.42284617e-01, -9.17146206e-02, -9.10572708e-02,\n",
       "        -1.75930947e-01, -3.27234447e-01, -1.77117825e-01,\n",
       "         1.42003953e-01,  2.44969428e-01,  2.46966451e-01,\n",
       "         2.98370123e-01,  2.04872996e-01, -8.97725224e-02,\n",
       "        -5.20934947e-02,  4.82459337e-01,  7.03523457e-01,\n",
       "         6.26044750e-01,  7.29706585e-01,  6.41967177e-01,\n",
       "        -3.75612415e-02, -1.03015732e-03,  9.58988786e-01,\n",
       "         1.35094690e+00,  1.16672647e+00,  1.37831330e+00,\n",
       "         1.22859466e+00,  1.80099696e-01,  2.46377736e-01,\n",
       "         1.78046775e+00,  2.23263192e+00,  1.69496143e+00,\n",
       "         2.14395976e+00,  1.42983127e+00,  6.56405985e-02,\n",
       "         4.42586899e-01,  2.08900094e+00,  2.50779748e+00,\n",
       "         1.99058425e+00,  2.42407250e+00,  1.30772090e+00,\n",
       "         3.33515048e-01,  5.60780108e-01,  1.94195199e+00,\n",
       "         2.17155623e+00,  1.61214054e+00,  2.15197706e+00]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_multi_pred_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-5.1732117e-01, -5.7452375e-01, -5.6893998e-01, -5.1721203e-01,\n",
       "        -4.6488130e-01, -4.1715536e-01, -3.9561772e-01, -4.5940390e-01,\n",
       "        -5.3340334e-01, -4.2652929e-01, -3.6178476e-01, -3.4965986e-01,\n",
       "        -2.9733273e-01, -2.6928478e-01, -3.3262813e-01, -4.0995851e-01,\n",
       "        -4.2662960e-01, -2.7396023e-01, -1.4228460e-01, -9.1714621e-02,\n",
       "        -9.1057241e-02, -1.7593101e-01, -3.2723454e-01, -1.7711782e-01,\n",
       "         1.4200398e-01,  2.4496943e-01,  2.4696645e-01,  2.9837018e-01,\n",
       "         2.0487297e-01, -8.9772537e-02, -5.2093413e-02,  4.8245931e-01,\n",
       "         7.0352340e-01,  6.2604475e-01,  7.2970659e-01,  6.4196730e-01,\n",
       "        -3.7561230e-02, -1.0301718e-03,  9.5898873e-01,  1.3509469e+00,\n",
       "         1.1667266e+00,  1.3783133e+00,  1.2285950e+00,  1.8009989e-01,\n",
       "         2.4637797e-01,  1.7804682e+00,  2.2326322e+00,  1.6949615e+00,\n",
       "         2.1439600e+00,  1.4298314e+00,  6.5640852e-02,  4.4258708e-01,\n",
       "         2.0890007e+00,  2.5077970e+00,  1.9905839e+00,  2.4240725e+00,\n",
       "         1.3077213e+00,  3.3351520e-01,  5.6077993e-01,  1.9419520e+00,\n",
       "         2.1715562e+00,  1.6121405e+00,  2.1519771e+00]], dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_multi_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n"
     ]
    }
   ],
   "source": [
    "# Assert if the result of TFLite model is consistent with the TF model.\n",
    "np.testing.assert_almost_equal(y_multi_pred, y_multi_pred_out, decimal=3)\n",
    "print(\"Done. The result of TensorFlow matches the result of TensorFlow Lite.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### future days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "status code :  200\n",
      "[[[2.0784218311309814, 2.3981120586395264, 6.659331321716309, 5.355687618255615, 2.045379400253296, 4.280978679656982, 7.5012922286987305]]]\n"
     ]
    }
   ],
   "source": [
    "# prepare input\n",
    "json_list_list_x = prepare_to_lambda_future(dataset)\n",
    "# REQUEST URL_PREDICT = 'https://yl0910jrga.execute-api.us-east-2.amazonaws.com/dev/infer' \n",
    "resp = requests.post(URL_PREDICT, json=json_list_list_x)\n",
    "print(\"status code : \", resp.status_code) \n",
    "print(resp.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.07842183, 2.39811206, 6.65933132, 5.35568762, 2.0453794 ,\n",
       "        4.28097868, 7.50129223]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_future_pred_out = retrieve_from_lambda(resp)      \n",
    "y_future_pred_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.0784218, 2.398112 , 6.659332 , 5.3556876, 2.0453794, 4.2809796,\n",
       "        7.501292 ]], dtype=float32)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_future_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. The result of TensorFlow matches the result of TensorFlow Lite.\n"
     ]
    }
   ],
   "source": [
    "# Assert if the result of TFLite model is consistent with the TF model.\n",
    "np.testing.assert_almost_equal(y_future_pred, y_future_pred_out, decimal=3)\n",
    "print(\"Done. The result of TensorFlow matches the result of TensorFlow Lite.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "260px",
    "width": "258px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "205px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
